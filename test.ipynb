{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/anhnh/miniconda3/envs/commonenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# t_tokenizer = AutoTokenizer.from_pretrained(\"nvidia/NV-Embed-v2\")\n",
    "t_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "\n",
    "def load(path):\n",
    "    with open(path) as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    return data\n",
    "\n",
    "dataset_names = [\"MAVEN\", \"ACE\"]\n",
    "perm_ids = [0, 1, 2, 3, 4]\n",
    "\n",
    "root=\"./data_incremental_2\"\n",
    "\n",
    "# for name in dataset_names:\n",
    "#     root_name = root + \"/\" + name + \"/\"\n",
    "#     test_path = root_name + f\"{name}.test.jsonl\"\n",
    "#     for \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAVEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trigger(tokens, span):\n",
    "    trigger = tokenizer.decode(tokens[span[0]:span[1] + 1])\n",
    "    step = span[1] - span[0] + 1\n",
    "    order = 0\n",
    "    for i in range(len(tokens) - step + 1):\n",
    "        if tokenizer.decode(tokens[i:i+step]) == trigger:\n",
    "            if i == span[0]:\n",
    "                break\n",
    "            order += 1\n",
    "    return trigger, order\n",
    "\n",
    "def get_span(tokenized, trigger, order, prefix_length=16):\n",
    "    step = len(t_tokenizer.tokenize(trigger))\n",
    "    n_order = 0\n",
    "    span = None\n",
    "    for i in range(len(tokenized) - step + 1):\n",
    "        if t_tokenizer.decoder.decode(tokenized[i:i+step]) == trigger:\n",
    "            if n_order == order:\n",
    "                span = [i+prefix_length, i+step-1+prefix_length]\n",
    "            n_order += 1\n",
    "\n",
    "    if not span:\n",
    "        step += 1\n",
    "        n_order = 0\n",
    "        for i in range(len(tokenized) - step + 1):\n",
    "            if t_tokenizer.decoder.decode(tokenized[i:i+step]) == trigger:\n",
    "                if n_order == order:\n",
    "                    span = [i+prefix_length, i+step-1+prefix_length]\n",
    "                n_order += 1\n",
    "    \n",
    "    if not span:\n",
    "        step += 1\n",
    "        n_order = 0\n",
    "        for i in range(len(tokenized) - step + 1):\n",
    "            if t_tokenizer.decoder.decode(tokenized[i:i+step]) == trigger:\n",
    "                if n_order == order:\n",
    "                    span = [i+prefix_length, i+step-1+prefix_length]\n",
    "                n_order += 1\n",
    "    \n",
    "    if not span:\n",
    "        step -= 2\n",
    "        order -= 1\n",
    "        n_order = 0\n",
    "        for i in range(len(tokenized) - step + 1):\n",
    "            if t_tokenizer.decoder.decode(tokenized[i:i+step]) == trigger:\n",
    "                if n_order == order:\n",
    "                    span = [i+prefix_length, i+step-1+prefix_length]\n",
    "                n_order += 1\n",
    "\n",
    "    return span\n",
    "\n",
    "def format_trigger(trigger):\n",
    "    if trigger == \"' s\": return \"'s\"\n",
    "    if trigger == \"' re\": return \"'re\"\n",
    "    if trigger == \"' ve\": return \"'ve\"\n",
    "    if trigger == \"' ll\": return \"'ll\"\n",
    "    if trigger == \"' d\": return \"'d\"\n",
    "    if trigger[0] == \"'\": return trigger[1:].strip()\n",
    "    if trigger[0] == \".\":\n",
    "        trigger = trigger[1:].strip()\n",
    "    try:\n",
    "        if trigger[-1] == \".\":\n",
    "            trigger = trigger[:-1].strip()\n",
    "    except:\n",
    "        pass \n",
    "    return trigger.replace(\"n't\", \" not\").strip()\n",
    "    # if trigger[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(\"./data_incremental_2/MAVEN/MAVEN.test.jsonl\")\n",
    "\n",
    "prefix = t_tokenizer.encode(\"Classify the type of event corresponding to each token in the following sentence:\")[:-1]\n",
    "\n",
    "count = 0\n",
    "\n",
    "with open(\"./data_incremental/MAVEN/MAVEN.test.jsonl\", 'w') as file:\n",
    "    for row in data:\n",
    "        tokens = row['piece_ids']\n",
    "        spans = row['span']\n",
    "        labels = row['label']\n",
    "        text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "        text = text.replace(\"n't\", \" not\")\n",
    "        new_ids = prefix + t_tokenizer.encode(text)[1:]\n",
    "        \n",
    "        n_spans = []\n",
    "        n_tokenized = t_tokenizer.tokenize(text)\n",
    "        for i, span in enumerate(spans):\n",
    "            trigger, order = get_trigger(tokens, span)\n",
    "            trigger = format_trigger(trigger)\n",
    "            n_span = get_span(n_tokenized, trigger, order)\n",
    "            if not n_span:\n",
    "                del labels[i]\n",
    "                print(trigger, span, order, text, tokens)\n",
    "                continue\n",
    "                \n",
    "                # if count > 20: break\n",
    "            n_spans.append(n_span)\n",
    "        \n",
    "        # if count > 20: break\n",
    "        \n",
    "        row[\"piece_ids\"] = new_ids\n",
    "        row[\"span\"] = n_spans\n",
    "        row[\"label\"] = labels\n",
    "\n",
    "        json_record = json.dumps(row)\n",
    "        file.write(json_record + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trigger(tokens, span):\n",
    "    trigger = tokenizer.decode(tokens[span[0]:span[1] + 1])\n",
    "    step = span[1] - span[0] + 1\n",
    "    order = 0\n",
    "    for i in range(len(tokens) - step + 1):\n",
    "        if tokenizer.decode(tokens[i:i+step]) == trigger:\n",
    "            if i == span[0]:\n",
    "                break\n",
    "            order += 1\n",
    "    return trigger, order\n",
    "\n",
    "def get_span(tokenized, trigger, order):\n",
    "    step = len(t_tokenizer.tokenize(trigger))\n",
    "    n_order = 0\n",
    "    span = None\n",
    "    for i in range(len(tokenized) - step + 1):\n",
    "        if t_tokenizer.decoder.decode(tokenized[i:i+step]).strip() == trigger:\n",
    "            if n_order == order:\n",
    "                span = [i, i+step-1]\n",
    "            n_order += 1\n",
    "    \n",
    "    if (not span) and (step > 1):\n",
    "        step -= 1\n",
    "        n_order = 0\n",
    "        for i in range(len(tokenized) - step + 1):\n",
    "            if t_tokenizer.decoder.decode(tokenized[i:i+step]).strip() == trigger:\n",
    "                if n_order == order:\n",
    "                    span = [i, i+step-1]\n",
    "                n_order += 1\n",
    "        step += 1\n",
    "    \n",
    "    if (not span) and (step > 2):\n",
    "        step -= 2\n",
    "        n_order = 0\n",
    "        for i in range(len(tokenized) - step + 1):\n",
    "            if t_tokenizer.decoder.decode(tokenized[i:i+step]).strip() == trigger:\n",
    "                if n_order == order:\n",
    "                    span = [i, i+step-1]\n",
    "                n_order += 1\n",
    "        step += 2\n",
    "\n",
    "    if not span:\n",
    "        step = len(t_tokenizer.tokenize(trigger)) + 1\n",
    "        n_order = 0\n",
    "        for i in range(len(tokenized) - step + 1):\n",
    "            if t_tokenizer.decoder.decode(tokenized[i:i+step]).strip() == trigger:\n",
    "                if n_order == order:\n",
    "                    span = [i, i+step-1]\n",
    "                n_order += 1\n",
    "    \n",
    "    if not span:\n",
    "        step = len(t_tokenizer.tokenize(trigger)) + 2\n",
    "        n_order = 0\n",
    "        for i in range(len(tokenized) - step + 1):\n",
    "            if t_tokenizer.decoder.decode(tokenized[i:i+step]).strip() == trigger:\n",
    "                if n_order == order:\n",
    "                    span = [i, i+step-1]\n",
    "                n_order += 1\n",
    "    \n",
    "    if not span:\n",
    "        step = len(t_tokenizer.tokenize(trigger))\n",
    "        order -= 1\n",
    "        n_order = 0\n",
    "        for i in range(len(tokenized) - step + 1):\n",
    "            if t_tokenizer.decoder.decode(tokenized[i:i+step]).strip() == trigger:\n",
    "                if n_order == order:\n",
    "                    span = [i, i+step-1]\n",
    "                n_order += 1\n",
    "        order += 1\n",
    "\n",
    "    if not span:\n",
    "        step = 1\n",
    "        n_order = 0\n",
    "        for i in range(len(tokenized) - step + 1):\n",
    "            if t_tokenizer.decoder.decode(tokenized[i:i+step]).strip() == trigger:\n",
    "                if n_order == order:\n",
    "                    span = [i, i+step-1]\n",
    "                n_order += 1\n",
    "    \n",
    "    if not span:\n",
    "        trigger = \"'\" + trigger\n",
    "        n_order = 0\n",
    "        step = len(t_tokenizer.tokenize(trigger))\n",
    "        for i in range(len(tokenized) - step + 1):\n",
    "            if t_tokenizer.decoder.decode(tokenized[i:i+step]).strip() == trigger:\n",
    "                if n_order == order:\n",
    "                    span = [i, i+step-1]\n",
    "                n_order += 1\n",
    "    span[0] += 1\n",
    "    span[1] += 1\n",
    "    return span\n",
    "\n",
    "def format_trigger(trigger):\n",
    "    if trigger == \"' s\": return \"'s\"\n",
    "    if trigger == \"' re\": return \"'re\"\n",
    "    if trigger == \"' ve\": return \"'ve\"\n",
    "    if trigger == \"' ll\": return \"'ll\"\n",
    "    if trigger == \"' d\": return \"'d\"\n",
    "    if trigger[0] == \"'\": return trigger[1:].strip()\n",
    "    if trigger[0] == \".\":\n",
    "        trigger = trigger[1:].strip()\n",
    "    try:\n",
    "        if trigger[-1] == \".\":\n",
    "            trigger = trigger[:-1].strip()\n",
    "    except:\n",
    "        pass \n",
    "    return trigger.replace(\"n't\", \" not\").strip()\n",
    "    # if trigger[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid(labels, spans):\n",
    "    valid_labels = []\n",
    "    for label in labels:\n",
    "        if label == 0:\n",
    "            break\n",
    "        valid_labels.append(label)\n",
    "    return valid_labels, spans[:len(valid_labels)]\n",
    "\n",
    "def get_ignore(spans):\n",
    "    ignores = []\n",
    "    for span in spans:\n",
    "        ignores += list(range(span[0], span[1] + 1))\n",
    "\n",
    "    return ignores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] hello - rrb - world - rrb - hello [SEP]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"hello - lrb - world - rrb - hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(\"./data_incremental_2/ACE/ACE.test.jsonl\")\n",
    "\n",
    "# prefix = t_tokenizer.encode(\"Classify the type of event corresponding to each token in the following sentence:\")\n",
    "prefix = []\n",
    "\n",
    "eos_token_id = t_tokenizer.eos_token_id\n",
    "count = 0\n",
    "\n",
    "with open(\"./data_incremental/ACE/ACE.test.jsonl\", 'w') as file:\n",
    "    for row in data:\n",
    "        tokens = row['piece_ids']\n",
    "        spans = row['span']\n",
    "        labels = row['label']\n",
    "\n",
    "        labels, spans = get_valid(labels, spans)\n",
    "\n",
    "        text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "        text = text.replace(\"n't\", \" not\").replace(\"- lrb -\", \"(\").replace(\"- rrb -\", \")\")\n",
    "        # new_ids = prefix + t_tokenizer.encode(text)[1:] + [eos_token_id\n",
    "        new_ids = t_tokenizer.encode(text) + [eos_token_id]\n",
    "        \n",
    "        n_spans = []\n",
    "        n_tokenized = t_tokenizer.tokenize(text)\n",
    "        for i, span in enumerate(spans):\n",
    "            trigger, order = get_trigger(tokens, span)\n",
    "            trigger = format_trigger(trigger)\n",
    "            n_span = get_span(n_tokenized, trigger, order)\n",
    "            if not n_span:\n",
    "                # del labels[i]\n",
    "                print(trigger, span, order, text, tokens)\n",
    "                continue\n",
    "            \n",
    "            # count += 1\n",
    "            # if count > 10: break\n",
    "            # print(trigger, span, n_span, order, text, tokens)\n",
    "            # print(trigger, t_tokenizer.decode(new_ids[n_span[0]: n_span[1] + 1]))\n",
    "            n_spans.append(n_span)\n",
    "            # print(trigger, t_tokenizer.decode(new_ids[n_span[0]: n_span[1] + 1]), span, n_span, order, text, new_ids)\n",
    "        \n",
    "        # if count > 10: break\n",
    "        ignores = get_ignore(n_spans)\n",
    "        for i in range(len(prefix)+1, len(new_ids)-1):\n",
    "            if i not in ignores:\n",
    "                n_spans.append([i,i])\n",
    "                labels.append(0)\n",
    "\n",
    "        \n",
    "        row[\"piece_ids\"] = new_ids\n",
    "        row[\"span\"] = n_spans\n",
    "        row[\"label\"] = labels\n",
    "\n",
    "        json_record = json.dumps(row)\n",
    "        file.write(json_record + '\\n')\n",
    "\n",
    "# for row in data:\n",
    "#     tokens = row['piece_ids']\n",
    "#     spans = row['span']\n",
    "#     labels = row['label']\n",
    "\n",
    "#     labels, spans = get_valid(labels, spans)\n",
    "\n",
    "#     text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "#     text = text.replace(\"n't\", \" not\")\n",
    "#     # new_ids = prefix + t_tokenizer.encode(text)[1:] + [eos_token_id\n",
    "#     new_ids = t_tokenizer.encode(text) + [eos_token_id]\n",
    "    \n",
    "#     n_spans = []\n",
    "#     n_tokenized = t_tokenizer.tokenize(text)\n",
    "#     for i, span in enumerate(spans):\n",
    "#         trigger, order = get_trigger(tokens, span)\n",
    "#         trigger = format_trigger(trigger)\n",
    "#         n_span = get_span(n_tokenized, trigger, order, len(prefix))\n",
    "#         if not n_span:\n",
    "#             # del labels[i]\n",
    "#             print(trigger, span, order, text, tokens)\n",
    "#             continue\n",
    "        \n",
    "#         # count += 1\n",
    "#         # if count > 10: break\n",
    "#         # print(trigger, span, n_span, order, text, tokens)\n",
    "#         # print(trigger, t_tokenizer.decode(new_ids[n_span[0]: n_span[1] + 1]))\n",
    "#         n_spans.append(n_span)\n",
    "    \n",
    "#     # if count > 10: break\n",
    "#     ignores = get_ignore(n_spans)\n",
    "#     for i in range(len(prefix), len(new_ids)):\n",
    "#         if i not in ignores:\n",
    "#             n_spans.append([i,i])\n",
    "#             labels.append(0)\n",
    "\n",
    "    \n",
    "#     row[\"piece_ids\"] = new_ids\n",
    "#     row[\"span\"] = n_spans\n",
    "#     row[\"label\"] = labels\n",
    "#     if len(new_ids) > 120:\n",
    "#         print(len(new_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token_id = t_tokenizer.eos_token_id\n",
    "\n",
    "for perm_id in [0, 1, 2, 3, 4]:\n",
    "    for dir in os.listdir(f\"./data_incremental_2/ACE/perm{perm_id}\"):\n",
    "        data = load(f\"./data_incremental_2/ACE/perm{perm_id}/{dir}\")\n",
    "\n",
    "        prefix = t_tokenizer.encode(\"Classify the type of event corresponding to each token in the following sentence:\")\n",
    "        prefix = []\n",
    "\n",
    "        with open(f\"./data_incremental/ACE/perm{perm_id}/{dir}\", 'w') as file:\n",
    "            for task in data:\n",
    "                for key in task.keys():\n",
    "                    for row in task[key]:\n",
    "                        tokens = row['piece_ids']\n",
    "                        spans = row['span']\n",
    "                        labels = row['label']\n",
    "\n",
    "                        labels, spans = get_valid(labels, spans)\n",
    "\n",
    "                        text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "                        text = text.replace(\"n't\", \" not\").replace(\"- lrb -\", \"(\").replace(\"- rrb -\", \")\")\n",
    "                        # new_ids = prefix + t_tokenizer.encode(text)[1:] + [eos_token_id]\n",
    "                        new_ids = t_tokenizer.encode(text) + [eos_token_id]\n",
    "                        \n",
    "                        n_spans = []\n",
    "                        n_tokenized = t_tokenizer.tokenize(text)\n",
    "                        for i, span in enumerate(spans):\n",
    "                            trigger, order = get_trigger(tokens, span)\n",
    "                            trigger = format_trigger(trigger)\n",
    "                            n_span = get_span(n_tokenized, trigger, order)\n",
    "                            if not n_span:\n",
    "                                del labels[i]\n",
    "                                print(trigger, span, order, text, tokens)\n",
    "                                continue\n",
    "                            \n",
    "                            n_spans.append(n_span)\n",
    "                            # print(trigger, t_tokenizer.decode(new_ids[n_span[0]: n_span[1] + 1]))\n",
    "                        \n",
    "                        # if count > 10: break\n",
    "                        ignores = get_ignore(n_spans)\n",
    "                        for i in range(len(prefix)+1, len(new_ids)-1):\n",
    "                            if i not in ignores:\n",
    "                                n_spans.append([i,i])\n",
    "                                labels.append(0)\n",
    "\n",
    "                        \n",
    "                        row[\"piece_ids\"] = new_ids\n",
    "                        row[\"span\"] = n_spans\n",
    "                        row[\"label\"] = labels\n",
    "\n",
    "                json_record = json.dumps(task)\n",
    "                file.write(json_record + '\\n')\n",
    "\n",
    "# eos_token_id = t_tokenizer.eos_token_id\n",
    "\n",
    "# for perm_id in [0, 1, 2, 3, 4]:\n",
    "#     for dir in os.listdir(f\"./data_incremental_2/ACE/perm{perm_id}\"):\n",
    "#         data = load(f\"./data_incremental_2/ACE/perm{perm_id}/{dir}\")\n",
    "\n",
    "#         prefix = t_tokenizer.encode(\"Classify the type of event corresponding to each token in the following sentence:\")\n",
    "#         prefix = []\n",
    "\n",
    "#         for task in data:\n",
    "#             for key in task.keys():\n",
    "#                 for row in task[key]:\n",
    "#                     tokens = row['piece_ids']\n",
    "#                     spans = row['span']\n",
    "#                     labels = row['label']\n",
    "\n",
    "#                     labels, spans = get_valid(labels, spans)\n",
    "\n",
    "#                     text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "#                     text = text.replace(\"n't\", \" not\")\n",
    "#                     # new_ids = prefix + t_tokenizer.encode(text)[1:] + [eos_token_id]\n",
    "#                     new_ids = t_tokenizer.encode(text) + [eos_token_id]\n",
    "                    \n",
    "#                     n_spans = []\n",
    "#                     n_tokenized = t_tokenizer.tokenize(text)\n",
    "#                     for i, span in enumerate(spans):\n",
    "#                         trigger, order = get_trigger(tokens, span)\n",
    "#                         trigger = format_trigger(trigger)\n",
    "#                         n_span = get_span(n_tokenized, trigger, order, len(prefix))\n",
    "#                         if not n_span:\n",
    "#                             del labels[i]\n",
    "#                             print(trigger, span, order, text, tokens)\n",
    "#                             continue\n",
    "                        \n",
    "#                         n_spans.append(n_span)\n",
    "                    \n",
    "#                     # if count > 10: break\n",
    "#                     ignores = get_ignore(n_spans)\n",
    "#                     for i in range(len(prefix), len(new_ids)):\n",
    "#                         if i not in ignores:\n",
    "#                             n_spans.append([i,i])\n",
    "#                             labels.append(0)\n",
    "\n",
    "                    \n",
    "#                     row[\"piece_ids\"] = new_ids\n",
    "#                     row[\"span\"] = n_spans\n",
    "#                     row[\"label\"] = labels\n",
    "\n",
    "#                     if len(new_ids) > 120:\n",
    "#                         print(len(new_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(\"23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/anhnh/miniconda3/envs/commonenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from llm2vec import LLM2Vec\n",
    "\n",
    "l2v = LLM2Vec.from_pretrained(\n",
    "    \"McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp\",\n",
    "    peft_model_name_or_path=\"McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-supervised\",\n",
    "    device_map=\"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    token=\"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\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = l2v.tokenize([\"i love you i love you<|end_of_text|>\", \"i love you i love you i love you\", \"i love you\"])\n",
    "del x['embed_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2v.model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|end_of_text|>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128001, 128001, 128000,     72,   3021,    499,    602,   3021,    499,\n",
       "         128001],\n",
       "        [128000,     72,   3021,    499,    602,   3021,    499,    602,   3021,\n",
       "            499],\n",
       "        [128001, 128001, 128001, 128001, 128001, 128001, 128000,     72,   3021,\n",
       "            499]]), 'attention_mask': tensor([[0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedd = l2v.model(**(x.to(\"cuda:0\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedd.last_hidden_state.to(torch.bfloat16).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = torch.nn.Linear(2,3, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 6], [7, 8], [12, 12]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "xx = [[1,1], [2,3], [7,7]]\n",
    "z = np.array(xx) + 5\n",
    "z.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/anhnh/miniconda3/envs/commonenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e160022b6144ddb569ed2ec006d088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56437b6a6fe41d3a299c54a13cf3fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's Lora trainable parameters:\n",
      "trainable params: 20,971,520 || all params: 7,525,896,192 || trainable%: 0.278658108814903\n"
     ]
    }
   ],
   "source": [
    "from model import LLM2VecED\n",
    "import torch\n",
    "\n",
    "model = LLM2VecED(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "prev_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prev_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m prev_model\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prev_model' is not defined"
     ]
    }
   ],
   "source": [
    "del prev_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {k: v for k, v in model.state_dict().items() if 'backbone' not in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['backbone.model.base_model.model.embed_tokens.weight', 'backbone.model.base_model.model.layers.0.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.0.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.0.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.0.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.0.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.0.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.0.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.0.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.0.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.0.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.0.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.0.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.0.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.0.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.0.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.0.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.0.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.0.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.0.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.0.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.0.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.0.input_layernorm.weight', 'backbone.model.base_model.model.layers.0.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.1.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.1.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.1.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.1.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.1.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.1.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.1.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.1.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.1.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.1.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.1.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.1.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.1.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.1.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.1.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.1.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.1.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.1.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.1.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.1.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.1.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.1.input_layernorm.weight', 'backbone.model.base_model.model.layers.1.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.2.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.2.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.2.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.2.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.2.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.2.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.2.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.2.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.2.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.2.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.2.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.2.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.2.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.2.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.2.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.2.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.2.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.2.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.2.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.2.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.2.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.2.input_layernorm.weight', 'backbone.model.base_model.model.layers.2.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.3.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.3.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.3.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.3.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.3.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.3.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.3.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.3.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.3.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.3.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.3.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.3.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.3.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.3.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.3.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.3.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.3.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.3.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.3.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.3.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.3.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.3.input_layernorm.weight', 'backbone.model.base_model.model.layers.3.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.4.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.4.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.4.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.4.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.4.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.4.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.4.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.4.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.4.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.4.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.4.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.4.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.4.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.4.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.4.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.4.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.4.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.4.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.4.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.4.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.4.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.4.input_layernorm.weight', 'backbone.model.base_model.model.layers.4.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.5.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.5.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.5.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.5.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.5.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.5.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.5.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.5.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.5.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.5.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.5.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.5.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.5.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.5.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.5.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.5.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.5.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.5.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.5.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.5.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.5.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.5.input_layernorm.weight', 'backbone.model.base_model.model.layers.5.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.6.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.6.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.6.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.6.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.6.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.6.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.6.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.6.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.6.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.6.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.6.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.6.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.6.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.6.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.6.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.6.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.6.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.6.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.6.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.6.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.6.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.6.input_layernorm.weight', 'backbone.model.base_model.model.layers.6.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.7.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.7.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.7.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.7.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.7.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.7.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.7.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.7.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.7.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.7.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.7.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.7.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.7.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.7.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.7.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.7.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.7.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.7.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.7.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.7.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.7.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.7.input_layernorm.weight', 'backbone.model.base_model.model.layers.7.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.8.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.8.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.8.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.8.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.8.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.8.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.8.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.8.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.8.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.8.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.8.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.8.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.8.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.8.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.8.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.8.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.8.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.8.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.8.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.8.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.8.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.8.input_layernorm.weight', 'backbone.model.base_model.model.layers.8.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.9.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.9.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.9.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.9.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.9.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.9.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.9.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.9.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.9.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.9.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.9.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.9.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.9.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.9.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.9.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.9.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.9.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.9.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.9.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.9.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.9.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.9.input_layernorm.weight', 'backbone.model.base_model.model.layers.9.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.10.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.10.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.10.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.10.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.10.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.10.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.10.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.10.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.10.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.10.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.10.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.10.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.10.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.10.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.10.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.10.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.10.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.10.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.10.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.10.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.10.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.10.input_layernorm.weight', 'backbone.model.base_model.model.layers.10.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.11.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.11.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.11.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.11.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.11.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.11.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.11.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.11.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.11.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.11.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.11.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.11.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.11.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.11.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.11.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.11.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.11.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.11.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.11.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.11.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.11.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.11.input_layernorm.weight', 'backbone.model.base_model.model.layers.11.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.12.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.12.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.12.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.12.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.12.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.12.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.12.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.12.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.12.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.12.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.12.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.12.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.12.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.12.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.12.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.12.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.12.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.12.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.12.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.12.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.12.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.12.input_layernorm.weight', 'backbone.model.base_model.model.layers.12.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.13.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.13.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.13.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.13.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.13.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.13.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.13.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.13.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.13.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.13.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.13.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.13.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.13.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.13.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.13.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.13.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.13.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.13.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.13.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.13.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.13.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.13.input_layernorm.weight', 'backbone.model.base_model.model.layers.13.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.14.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.14.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.14.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.14.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.14.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.14.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.14.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.14.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.14.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.14.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.14.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.14.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.14.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.14.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.14.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.14.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.14.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.14.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.14.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.14.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.14.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.14.input_layernorm.weight', 'backbone.model.base_model.model.layers.14.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.15.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.15.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.15.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.15.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.15.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.15.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.15.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.15.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.15.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.15.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.15.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.15.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.15.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.15.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.15.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.15.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.15.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.15.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.15.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.15.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.15.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.15.input_layernorm.weight', 'backbone.model.base_model.model.layers.15.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.16.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.16.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.16.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.16.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.16.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.16.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.16.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.16.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.16.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.16.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.16.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.16.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.16.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.16.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.16.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.16.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.16.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.16.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.16.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.16.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.16.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.16.input_layernorm.weight', 'backbone.model.base_model.model.layers.16.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.17.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.17.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.17.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.17.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.17.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.17.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.17.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.17.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.17.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.17.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.17.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.17.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.17.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.17.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.17.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.17.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.17.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.17.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.17.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.17.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.17.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.17.input_layernorm.weight', 'backbone.model.base_model.model.layers.17.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.18.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.18.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.18.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.18.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.18.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.18.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.18.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.18.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.18.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.18.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.18.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.18.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.18.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.18.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.18.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.18.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.18.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.18.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.18.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.18.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.18.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.18.input_layernorm.weight', 'backbone.model.base_model.model.layers.18.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.19.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.19.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.19.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.19.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.19.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.19.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.19.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.19.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.19.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.19.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.19.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.19.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.19.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.19.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.19.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.19.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.19.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.19.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.19.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.19.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.19.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.19.input_layernorm.weight', 'backbone.model.base_model.model.layers.19.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.20.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.20.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.20.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.20.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.20.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.20.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.20.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.20.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.20.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.20.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.20.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.20.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.20.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.20.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.20.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.20.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.20.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.20.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.20.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.20.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.20.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.20.input_layernorm.weight', 'backbone.model.base_model.model.layers.20.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.21.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.21.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.21.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.21.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.21.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.21.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.21.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.21.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.21.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.21.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.21.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.21.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.21.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.21.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.21.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.21.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.21.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.21.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.21.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.21.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.21.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.21.input_layernorm.weight', 'backbone.model.base_model.model.layers.21.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.22.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.22.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.22.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.22.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.22.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.22.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.22.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.22.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.22.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.22.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.22.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.22.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.22.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.22.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.22.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.22.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.22.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.22.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.22.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.22.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.22.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.22.input_layernorm.weight', 'backbone.model.base_model.model.layers.22.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.23.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.23.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.23.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.23.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.23.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.23.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.23.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.23.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.23.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.23.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.23.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.23.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.23.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.23.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.23.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.23.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.23.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.23.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.23.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.23.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.23.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.23.input_layernorm.weight', 'backbone.model.base_model.model.layers.23.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.24.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.24.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.24.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.24.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.24.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.24.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.24.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.24.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.24.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.24.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.24.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.24.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.24.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.24.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.24.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.24.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.24.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.24.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.24.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.24.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.24.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.24.input_layernorm.weight', 'backbone.model.base_model.model.layers.24.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.25.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.25.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.25.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.25.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.25.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.25.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.25.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.25.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.25.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.25.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.25.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.25.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.25.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.25.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.25.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.25.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.25.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.25.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.25.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.25.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.25.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.25.input_layernorm.weight', 'backbone.model.base_model.model.layers.25.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.26.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.26.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.26.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.26.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.26.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.26.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.26.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.26.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.26.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.26.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.26.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.26.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.26.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.26.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.26.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.26.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.26.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.26.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.26.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.26.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.26.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.26.input_layernorm.weight', 'backbone.model.base_model.model.layers.26.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.27.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.27.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.27.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.27.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.27.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.27.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.27.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.27.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.27.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.27.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.27.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.27.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.27.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.27.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.27.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.27.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.27.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.27.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.27.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.27.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.27.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.27.input_layernorm.weight', 'backbone.model.base_model.model.layers.27.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.28.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.28.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.28.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.28.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.28.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.28.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.28.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.28.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.28.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.28.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.28.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.28.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.28.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.28.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.28.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.28.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.28.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.28.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.28.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.28.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.28.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.28.input_layernorm.weight', 'backbone.model.base_model.model.layers.28.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.29.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.29.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.29.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.29.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.29.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.29.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.29.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.29.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.29.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.29.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.29.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.29.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.29.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.29.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.29.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.29.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.29.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.29.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.29.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.29.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.29.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.29.input_layernorm.weight', 'backbone.model.base_model.model.layers.29.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.30.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.30.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.30.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.30.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.30.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.30.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.30.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.30.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.30.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.30.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.30.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.30.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.30.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.30.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.30.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.30.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.30.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.30.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.30.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.30.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.30.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.30.input_layernorm.weight', 'backbone.model.base_model.model.layers.30.post_attention_layernorm.weight', 'backbone.model.base_model.model.layers.31.self_attn.q_proj.base_layer.weight', 'backbone.model.base_model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.31.self_attn.q_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.31.self_attn.q_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.31.self_attn.k_proj.base_layer.weight', 'backbone.model.base_model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.31.self_attn.k_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.31.self_attn.k_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.31.self_attn.v_proj.base_layer.weight', 'backbone.model.base_model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.31.self_attn.v_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.31.self_attn.v_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.31.self_attn.o_proj.base_layer.weight', 'backbone.model.base_model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.31.self_attn.o_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.31.self_attn.o_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.31.mlp.gate_proj.base_layer.weight', 'backbone.model.base_model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.31.mlp.gate_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.31.mlp.gate_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.31.mlp.up_proj.base_layer.weight', 'backbone.model.base_model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.31.mlp.up_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.31.mlp.up_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.31.mlp.down_proj.base_layer.weight', 'backbone.model.base_model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'backbone.model.base_model.model.layers.31.mlp.down_proj.lora_A.test.weight', 'backbone.model.base_model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'backbone.model.base_model.model.layers.31.mlp.down_proj.lora_B.test.weight', 'backbone.model.base_model.model.layers.31.input_layernorm.weight', 'backbone.model.base_model.model.layers.31.post_attention_layernorm.weight', 'backbone.model.base_model.model.norm.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict=state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/anhnh/miniconda3/envs/commonenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9769cfbced4a16b9447e60b0c4071b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4006d93881b849f89350132c850b91a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llm2vec import LLM2Vec\n",
    "import torch\n",
    "\n",
    "backbone = LLM2Vec.from_pretrained(\n",
    "            \"McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp\",\n",
    "            peft_model_name_or_path=\"McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-supervised\",\n",
    "            device_map=\"cuda:0\",\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            merge_peft=True,\n",
    "            pooling_mode=\"mean\",\n",
    "            max_length=120,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaBiModel(\n",
       "  (embed_tokens): Embedding(128256, 4096)\n",
       "  (layers): ModuleList(\n",
       "    (0-31): 32 x ModifiedLlamaDecoderLayer(\n",
       "      (self_attn): ModifiedLlamaSdpaAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (mlp): LlamaMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): LlamaRMSNorm()\n",
       "      (post_attention_layernorm): LlamaRMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): LlamaRMSNorm()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "backbone.model = PeftModel.from_pretrained(backbone.model, \"./outputs/early_stop/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaBiModel(\n",
       "      (embed_tokens): Embedding(128256, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x ModifiedLlamaDecoderLayer(\n",
       "          (self_attn): ModifiedLlamaSdpaAttention(\n",
       "            (q_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (k_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (v_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (o_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=14336, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (up_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=14336, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (down_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=14336, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm()\n",
       "          (post_attention_layernorm): LlamaRMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backbone.model.load_adapter(\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['base_model.model.embed_tokens.weight', 'base_model.model.layers.0.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.0.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.0.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.0.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.0.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.0.mlp.up_proj.base_layer.weight', 'base_model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.0.mlp.down_proj.base_layer.weight', 'base_model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.0.input_layernorm.weight', 'base_model.model.layers.0.post_attention_layernorm.weight', 'base_model.model.layers.1.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.1.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.1.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.1.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.1.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.1.mlp.up_proj.base_layer.weight', 'base_model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.1.mlp.down_proj.base_layer.weight', 'base_model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.1.input_layernorm.weight', 'base_model.model.layers.1.post_attention_layernorm.weight', 'base_model.model.layers.2.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.2.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.2.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.2.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.2.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.2.mlp.up_proj.base_layer.weight', 'base_model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.2.mlp.down_proj.base_layer.weight', 'base_model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.2.input_layernorm.weight', 'base_model.model.layers.2.post_attention_layernorm.weight', 'base_model.model.layers.3.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.3.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.3.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.3.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.3.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.3.mlp.up_proj.base_layer.weight', 'base_model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.3.mlp.down_proj.base_layer.weight', 'base_model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.3.input_layernorm.weight', 'base_model.model.layers.3.post_attention_layernorm.weight', 'base_model.model.layers.4.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.4.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.4.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.4.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.4.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.4.mlp.up_proj.base_layer.weight', 'base_model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.4.mlp.down_proj.base_layer.weight', 'base_model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.4.input_layernorm.weight', 'base_model.model.layers.4.post_attention_layernorm.weight', 'base_model.model.layers.5.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.5.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.5.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.5.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.5.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.5.mlp.up_proj.base_layer.weight', 'base_model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.5.mlp.down_proj.base_layer.weight', 'base_model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.5.input_layernorm.weight', 'base_model.model.layers.5.post_attention_layernorm.weight', 'base_model.model.layers.6.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.6.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.6.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.6.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.6.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.6.mlp.up_proj.base_layer.weight', 'base_model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.6.mlp.down_proj.base_layer.weight', 'base_model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.6.input_layernorm.weight', 'base_model.model.layers.6.post_attention_layernorm.weight', 'base_model.model.layers.7.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.7.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.7.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.7.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.7.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.7.mlp.up_proj.base_layer.weight', 'base_model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.7.mlp.down_proj.base_layer.weight', 'base_model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.7.input_layernorm.weight', 'base_model.model.layers.7.post_attention_layernorm.weight', 'base_model.model.layers.8.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.8.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.8.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.8.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.8.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.8.mlp.up_proj.base_layer.weight', 'base_model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.8.mlp.down_proj.base_layer.weight', 'base_model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.8.input_layernorm.weight', 'base_model.model.layers.8.post_attention_layernorm.weight', 'base_model.model.layers.9.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.9.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.9.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.9.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.9.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.9.mlp.up_proj.base_layer.weight', 'base_model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.9.mlp.down_proj.base_layer.weight', 'base_model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.9.input_layernorm.weight', 'base_model.model.layers.9.post_attention_layernorm.weight', 'base_model.model.layers.10.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.10.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.10.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.10.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.10.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.10.mlp.up_proj.base_layer.weight', 'base_model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.10.mlp.down_proj.base_layer.weight', 'base_model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.10.input_layernorm.weight', 'base_model.model.layers.10.post_attention_layernorm.weight', 'base_model.model.layers.11.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.11.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.11.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.11.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.11.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.11.mlp.up_proj.base_layer.weight', 'base_model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.11.mlp.down_proj.base_layer.weight', 'base_model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.11.input_layernorm.weight', 'base_model.model.layers.11.post_attention_layernorm.weight', 'base_model.model.layers.12.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.12.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.12.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.12.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.12.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.12.mlp.up_proj.base_layer.weight', 'base_model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.12.mlp.down_proj.base_layer.weight', 'base_model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.12.input_layernorm.weight', 'base_model.model.layers.12.post_attention_layernorm.weight', 'base_model.model.layers.13.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.13.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.13.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.13.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.13.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.13.mlp.up_proj.base_layer.weight', 'base_model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.13.mlp.down_proj.base_layer.weight', 'base_model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.13.input_layernorm.weight', 'base_model.model.layers.13.post_attention_layernorm.weight', 'base_model.model.layers.14.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.14.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.14.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.14.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.14.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.14.mlp.up_proj.base_layer.weight', 'base_model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.14.mlp.down_proj.base_layer.weight', 'base_model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.14.input_layernorm.weight', 'base_model.model.layers.14.post_attention_layernorm.weight', 'base_model.model.layers.15.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.15.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.15.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.15.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.15.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.15.mlp.up_proj.base_layer.weight', 'base_model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.15.mlp.down_proj.base_layer.weight', 'base_model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.15.input_layernorm.weight', 'base_model.model.layers.15.post_attention_layernorm.weight', 'base_model.model.layers.16.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.16.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.16.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.16.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.16.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.16.mlp.up_proj.base_layer.weight', 'base_model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.16.mlp.down_proj.base_layer.weight', 'base_model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.16.input_layernorm.weight', 'base_model.model.layers.16.post_attention_layernorm.weight', 'base_model.model.layers.17.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.17.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.17.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.17.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.17.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.17.mlp.up_proj.base_layer.weight', 'base_model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.17.mlp.down_proj.base_layer.weight', 'base_model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.17.input_layernorm.weight', 'base_model.model.layers.17.post_attention_layernorm.weight', 'base_model.model.layers.18.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.18.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.18.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.18.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.18.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.18.mlp.up_proj.base_layer.weight', 'base_model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.18.mlp.down_proj.base_layer.weight', 'base_model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.18.input_layernorm.weight', 'base_model.model.layers.18.post_attention_layernorm.weight', 'base_model.model.layers.19.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.19.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.19.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.19.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.19.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.19.mlp.up_proj.base_layer.weight', 'base_model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.19.mlp.down_proj.base_layer.weight', 'base_model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.19.input_layernorm.weight', 'base_model.model.layers.19.post_attention_layernorm.weight', 'base_model.model.layers.20.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.20.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.20.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.20.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.20.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.20.mlp.up_proj.base_layer.weight', 'base_model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.20.mlp.down_proj.base_layer.weight', 'base_model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.20.input_layernorm.weight', 'base_model.model.layers.20.post_attention_layernorm.weight', 'base_model.model.layers.21.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.21.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.21.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.21.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.21.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.21.mlp.up_proj.base_layer.weight', 'base_model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.21.mlp.down_proj.base_layer.weight', 'base_model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.21.input_layernorm.weight', 'base_model.model.layers.21.post_attention_layernorm.weight', 'base_model.model.layers.22.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.22.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.22.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.22.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.22.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.22.mlp.up_proj.base_layer.weight', 'base_model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.22.mlp.down_proj.base_layer.weight', 'base_model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.22.input_layernorm.weight', 'base_model.model.layers.22.post_attention_layernorm.weight', 'base_model.model.layers.23.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.23.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.23.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.23.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.23.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.23.mlp.up_proj.base_layer.weight', 'base_model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.23.mlp.down_proj.base_layer.weight', 'base_model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.23.input_layernorm.weight', 'base_model.model.layers.23.post_attention_layernorm.weight', 'base_model.model.layers.24.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.24.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.24.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.24.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.24.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.24.mlp.up_proj.base_layer.weight', 'base_model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.24.mlp.down_proj.base_layer.weight', 'base_model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.24.input_layernorm.weight', 'base_model.model.layers.24.post_attention_layernorm.weight', 'base_model.model.layers.25.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.25.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.25.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.25.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.25.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.25.mlp.up_proj.base_layer.weight', 'base_model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.25.mlp.down_proj.base_layer.weight', 'base_model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.25.input_layernorm.weight', 'base_model.model.layers.25.post_attention_layernorm.weight', 'base_model.model.layers.26.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.26.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.26.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.26.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.26.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.26.mlp.up_proj.base_layer.weight', 'base_model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.26.mlp.down_proj.base_layer.weight', 'base_model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.26.input_layernorm.weight', 'base_model.model.layers.26.post_attention_layernorm.weight', 'base_model.model.layers.27.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.27.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.27.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.27.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.27.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.27.mlp.up_proj.base_layer.weight', 'base_model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.27.mlp.down_proj.base_layer.weight', 'base_model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.27.input_layernorm.weight', 'base_model.model.layers.27.post_attention_layernorm.weight', 'base_model.model.layers.28.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.28.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.28.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.28.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.28.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.28.mlp.up_proj.base_layer.weight', 'base_model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.28.mlp.down_proj.base_layer.weight', 'base_model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.28.input_layernorm.weight', 'base_model.model.layers.28.post_attention_layernorm.weight', 'base_model.model.layers.29.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.29.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.29.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.29.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.29.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.29.mlp.up_proj.base_layer.weight', 'base_model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.29.mlp.down_proj.base_layer.weight', 'base_model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.29.input_layernorm.weight', 'base_model.model.layers.29.post_attention_layernorm.weight', 'base_model.model.layers.30.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.30.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.30.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.30.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.30.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.30.mlp.up_proj.base_layer.weight', 'base_model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.30.mlp.down_proj.base_layer.weight', 'base_model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.30.input_layernorm.weight', 'base_model.model.layers.30.post_attention_layernorm.weight', 'base_model.model.layers.31.self_attn.q_proj.base_layer.weight', 'base_model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.layers.31.self_attn.k_proj.base_layer.weight', 'base_model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.31.self_attn.v_proj.base_layer.weight', 'base_model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.31.self_attn.o_proj.base_layer.weight', 'base_model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.model.layers.31.mlp.gate_proj.base_layer.weight', 'base_model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'base_model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'base_model.model.layers.31.mlp.up_proj.base_layer.weight', 'base_model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'base_model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'base_model.model.layers.31.mlp.down_proj.base_layer.weight', 'base_model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'base_model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'base_model.model.layers.31.input_layernorm.weight', 'base_model.model.layers.31.post_attention_layernorm.weight', 'base_model.model.norm.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.backbone.model.load_adapter(\"./outputs/early_stop/test\", adapter_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/anhnh/miniconda3/envs/commonenv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-66dc0f55-7240e45859f6a4084e12c9e5;6d238209-4a39-44f6-baaa-75dc898cbda2)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.backbone.model.save_pretrained(\"./outputs/early_stop/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4923973083496094"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Operation\n",
    "model.to('cuda:1')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# End the timer\n",
    "time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0 CUDA_LAUNCH_BLOCKING=1 python train_first_task.py \\\n",
    "                --data-root ./data_incremental \\\n",
    "                --dataset ACE \\\n",
    "                --backbone bert-base-uncased \\\n",
    "                --lr 2e-5 \\\n",
    "                --decay 1e-4 \\\n",
    "                --no-freeze-bert \\\n",
    "                --shot-num 1 \\\n",
    "                --batch-size 4 \\\n",
    "                --device cuda:0 \\\n",
    "                --log \\\n",
    "                --log-dir ./outputs/log_incremental/temp7_submax/first_wo_UCL+TCL/ \\\n",
    "                --log-name ashuffle_lnone_r5 \\\n",
    "                --dweight_loss \\\n",
    "                --rep-aug mean \\\n",
    "                --distill mul \\\n",
    "                --epoch 20 \\\n",
    "                --class-num 20 \\\n",
    "                --single-label \\\n",
    "                --cl-aug shuffle \\\n",
    "                --aug-repeat-times 5 \\\n",
    "                --joint-da-loss none \\\n",
    "                --sub-max \\\n",
    "                --cl_temp 0.07 \\\n",
    "                --tlcl \\\n",
    "                --ucl \\\n",
    "                --skip-first-cl ucl+tlcl \\\n",
    "                --perm-id 0 \\\n",
    "                --early-stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=1 CUDA_LAUNCH_BLOCKING=1 python train.py                 --data-root ./data_incremental                 --dataset ACE                 --backbone bert-base-uncased                 --lr 2e-5                 --decay 1e-4                 --no-freeze-bert                 --shot-num 1                 --batch-size 4                 --device cuda:0                 --log                 --log-dir ./outputs/log_incremental/temp7_submax/first_wo_UCL+TCL/                 --log-name ashuffle_lnone_r5                 --dweight_loss                 --rep-aug mean                 --distill mul                 --epoch 20                 --class-num 20                 --single-label                 --cl-aug shuffle                 --aug-repeat-times 5                 --joint-da-loss none                 --sub-max                 --cl_temp 0.07                 --tlcl                 --ucl                 --skip-first-cl ucl+tlcl                 --perm-id 0 --early-stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1 python train.py \\\n",
    "                            --data-root ./data_incremental \\\n",
    "                            --dataset ACE \\\n",
    "                            --backbone llm2vec \\\n",
    "                            --lr 2e-5 \\\n",
    "                            --decay 1e-4 \\\n",
    "                            --no-freeze-bert \\\n",
    "                            --shot-num 1 \\\n",
    "                            --batch-size 1 \\\n",
    "                            --device cuda:0 \\\n",
    "                            --device2 cuda:1 \\\n",
    "                            --log \\\n",
    "                            --log-dir ./outputs/log_incremental/temp7_submax/first_wo_UCL+TCL/ \\\n",
    "                            --log-name a0_lnone_r5 \\\n",
    "                            --dweight_loss \\\n",
    "                            --rep-aug mean \\\n",
    "                            --distill mul \\\n",
    "                            --epochs 20 \\\n",
    "                            --class-num 10 \\\n",
    "                            --single-label \\\n",
    "                            --cl-aug shuffle \\\n",
    "                            --aug-repeat-times 5 \\\n",
    "                            --joint-da-loss none \\\n",
    "                            --sub-max \\\n",
    "                            --cl_temp 0.07 \\\n",
    "                            --tlcl \\\n",
    "                            --ucl \\\n",
    "                            --skip-first-cl ucl+tlcl \\\n",
    "                            --perm-id 0 \\\n",
    "                            --early-stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "do\n",
    "    for j in 5 10\n",
    "    do\n",
    "        for k in shuffle\n",
    "        do\n",
    "            for m in 10 20\n",
    "            do\n",
    "                for n in ACE MAVEN\n",
    "                do\n",
    "                    python train.py \\\n",
    "                        --data-root ./data_incremental \\\n",
    "                        --dataset $n \\\n",
    "                        --backbone bert-base-uncased \\\n",
    "                        --lr 2e-5 \\\n",
    "                        --decay 1e-4 \\\n",
    "                        --no-freeze-bert \\\n",
    "                        --shot-num $j \\\n",
    "                        --batch-size 4 \\\n",
    "                        --device cuda:4 \\\n",
    "                        --log \\\n",
    "                        --log-dir ./outputs/log_incremental/temp7_submax/first_wo_UCL+TCL/ \\\n",
    "                        --log-name a${k}_l${l}_r${i} \\\n",
    "                        --dweight_loss \\\n",
    "                        --rep-aug mean \\\n",
    "                        --distill mul \\\n",
    "                        --epoch 30 \\\n",
    "                        --class-num $m \\\n",
    "                        --single-label \\\n",
    "                        --cl-aug $k \\\n",
    "                        --aug-repeat-times $i \\\n",
    "                        --joint-da-loss $l \\\n",
    "                        --sub-max \\\n",
    "                        --cl_temp 0.07 \\\n",
    "                        --tlcl \\\n",
    "                        --ucl \\\n",
    "                        --skip-first-cl ucl+tlcl\n",
    "                done\n",
    "            done\n",
    "        done\n",
    "    done\n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1], [22, 22], [23, 2'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"{\"9\": [{\"piece_ids\": [128000, 2201, 18084, 11, 912, 384, 482, 8232, 11, 12197, 527, 279, 1193, 2723, 311, 2162, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[9, 9], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16]]}, {\"piece_ids\": [128000, 906, 36646, 1057, 77541, 389, 94496, 62366, 389, 220, 605, 611, 220, 2148, 611, 220, 1049, 19, 482, 499, 1205, 311, 3729, 94496, 13306, 9476, 323, 2610, 422, 814, 617, 904, 13306, 611, 43901, 14519, 2561, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[22, 22], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37]]}, {\"piece_ids\": [128000, 276, 2362, 4333, 11, 90744, 764, 38430, 83, 315, 597, 15564, 675, 11, 13819, 11, 6051, 49614, 311, 2610, 922, 7294, 482, 15443, 439, 459, 4360, 369, 36999, 689, 12345, 1900, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[17, 17], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32]]}, {\"piece_ids\": [128000, 438, 499, 1518, 74506, 36125, 18178, 323, 813, 7555, 24154, 6853, 889, 574, 7556, 449, 603, 389, 279, 21186, 279, 93463, 6693, 994, 279, 2835, 3782, 304, 315, 279, 17629, 315, 279, 281, 13, 297, 13, 289, 13, 274, 323, 1364, 574, 3025, 311, 3371, 603, 389, 279, 21186, 439, 584, 1047, 1884, 9364, 709, 389, 3805, 11, 1364, 11054, 1077, 10177, 323, 2324, 1120, 2751, 2731, 323, 2731, 369, 1077, 1306, 430, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[14, 14], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55], [56, 56], [57, 57], [58, 58], [59, 59], [60, 60], [61, 61], [62, 62], [63, 63], [64, 64], [65, 65], [66, 66], [67, 67], [68, 68], [69, 69], [70, 70], [71, 71], [72, 72], [73, 73], [74, 74]]}, {\"piece_ids\": [128000, 1712, 1457, 369, 1595, 1595, 4027, 1445, 41610, 1405, 1057, 289, 81057, 323, 597, 67824, 7359, 323, 4885, 323, 23531, 1314, 304, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[21, 21], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [22, 22], [23, 23]]}, {\"piece_ids\": [128000, 72, 617, 25559, 279, 577, 4575, 323, 3309, 1124, 922, 433, 779, 814, 649, 1817, 279, 71232, 482, 326, 10910, 482, 1364, 596, 1027, 3815, 420, 264, 1317, 892, 482, 436, 10910, 482, 323, 311, 3371, 757, 422, 1364, 596, 3604, 264, 9879, 4562, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[3, 3], [1, 1], [2, 2], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45]]}, {\"piece_ids\": [128000, 64750, 21467, 11, 2204, 74884, 32606, 11, 719, 682, 527, 16026, 11, 555, 279, 892, 872, 12197, 636, 1203, 311, 279, 577, 13, 274, 2637, 814, 2288, 690, 5246, 387, 14836, 2162, 13, 128001], \"label\": [9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[17, 17], [31, 31], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [32, 32], [33, 33]]}, {\"piece_ids\": [128000, 383, 2751, 389, 264, 11213, 311, 459, 83957, 3813, 11, 994, 20673, 648, 2751, 264, 2132, 4641, 1650, 505, 264, 11213, 65022, 13, 128001], \"label\": [2, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [18, 18], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23]]}, {\"piece_ids\": [128000, 383, 29782, 603, 1457, 505, 94771, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0], \"span\": [[2, 2], [1, 1], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7]]}, {\"piece_ids\": [128000, 383, 6944, 311, 1650, 813, 3450, 304, 305, 14753, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 4], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10]]}, {\"piece_ids\": [128000, 275, 574, 1071, 311, 387, 58272, 309, 9222, 49535, 596, 2077, 311, 264, 6661, 505, 813, 80115, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[14, 14], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18]]}, {\"piece_ids\": [128000, 72, 574, 389, 279, 4641, 449, 24154, 6853, 690, 12663, 13985, 11, 994, 1364, 5602, 1884, 1176, 9364, 389, 61558, 315, 1077, 10177, 11, 323, 1364, 48494, 291, 449, 18454, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31]]}, {\"piece_ids\": [128000, 72, 1781, 1148, 568, 6267, 757, 922, 574, 279, 2144, 430, 279, 958, 482, 9266, 1920, 11, 1405, 584, 617, 682, 1521, 282, 8385, 323, 9476, 315, 12437, 323, 272, 689, 323, 18205, 11, 323, 1148, 617, 499, 11, 6532, 304, 37539, 1113, 1521, 68034, 11, 433, 5097, 892, 311, 1505, 704, 1148, 11478, 814, 617, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55], [56, 56], [57, 57]]}, {\"piece_ids\": [128000, 576, 892, 11, 814, 3987, 279, 69938, 690, 3350, 1203, 449, 11503, 311, 872, 4860, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[9, 9], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16]]}, {\"piece_ids\": [128000, 66305, 603, 389, 279, 4641, 374, 279, 17352, 315, 503, 19950, 11, 259, 22181, 11, 1181, 645, 37500, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19]]}, {\"piece_ids\": [128000, 383, 3288, 3892, 12197, 311, 279, 4379, 323, 279, 3772, 2391, 430, 892, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 4], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14]]}, {\"piece_ids\": [128000, 258, 813, 3766, 6661, 2162, 11, 74506, 18178, 94441, 1437, 96274, 1550, 539, 3371, 813, 3070, 279, 2539, 3649, 922, 813, 1176, 12896, 9131, 13, 128001], \"label\": [1, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[23, 23], [14, 14], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [24, 24], [25, 25]]}, {\"piece_ids\": [128000, 2201, 18084, 11, 912, 384, 482, 8232, 11, 12197, 527, 279, 1193, 2723, 311, 2162, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[9, 9], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16]]}, {\"piece_ids\": [128000, 438, 499, 1518, 74506, 36125, 18178, 323, 813, 7555, 24154, 6853, 889, 574, 7556, 449, 603, 389, 279, 21186, 279, 93463, 6693, 994, 279, 2835, 3782, 304, 315, 279, 17629, 315, 279, 281, 13, 297, 13, 289, 13, 274, 323, 1364, 574, 3025, 311, 3371, 603, 389, 279, 21186, 439, 584, 1047, 1884, 9364, 709, 389, 3805, 11, 1364, 11054, 1077, 10177, 323, 2324, 1120, 2751, 2731, 323, 2731, 369, 1077, 1306, 430, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[14, 14], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55], [56, 56], [57, 57], [58, 58], [59, 59], [60, 60], [61, 61], [62, 62], [63, 63], [64, 64], [65, 65], [66, 66], [67, 67], [68, 68], [69, 69], [70, 70], [71, 71], [72, 72], [73, 73], [74, 74]]}, {\"piece_ids\": [128000, 1712, 1457, 369, 1595, 1595, 4027, 1445, 41610, 1405, 1057, 289, 81057, 323, 597, 67824, 7359, 323, 4885, 323, 23531, 1314, 304, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[21, 21], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [22, 22], [23, 23]]}, {\"piece_ids\": [128000, 11998, 261, 551, 3235, 449, 279, 6945, 11, 279, 11213, 65022, 6267, 264, 6661, 5605, 1364, 574, 550, 4768, 369, 26128, 596, 6220, 471, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[14, 14], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25]]}, {\"piece_ids\": [128000, 331, 329, 305, 729, 3258, 11, 505, 6762, 40153, 11, 36999, 689, 11, 14238, 11, 1595, 1595, 48687, 11, 436, 29578, 323, 43627, 617, 682, 7447, 482, 7239, 18160, 5707, 12789, 449, 58272, 309, 304, 6348, 37406, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[14, 14], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38]]}, {\"piece_ids\": [128000, 82977, 264, 10015, 4641, 1650, 449, 872, 4538, 505, 37700, 11748, 389, 274, 399, 29684, 279, 6916, 4691, 279, 3995, 3070, 539, 311, 636, 1139, 904, 3230, 3649, 922, 1148, 7077, 2391, 872, 4538, 596, 12602, 323, 4984, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39]]}, {\"piece_ids\": [128000, 72, 3077, 15243, 311, 1274, 505, 44049, 18987, 11, 10035, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[3, 3], [1, 1], [2, 2], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11]]}, {\"piece_ids\": [128000, 9638, 4477, 11, 499, 1440, 11, 374, 7170, 2663, 264, 5675, 1989, 304, 420, 4325, 315, 14683, 10758, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[2, 2], [1, 1], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19]]}, {\"piece_ids\": [128000, 11998, 261, 551, 3235, 449, 279, 6945, 11, 279, 11213, 65022, 6267, 264, 6661, 5605, 1364, 574, 550, 4768, 369, 26128, 596, 6220, 471, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[14, 14], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25]]}, {\"piece_ids\": [128000, 72, 15243, 311, 19607, 7019, 616, 420, 6693, 389, 279, 4641, 264, 2766, 11, 323, 433, 596, 539, 11, 602, 1781, 499, 1205, 311, 1095, 279, 16174, 25760, 389, 430, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[2, 2], [1, 1], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31]]}, {\"piece_ids\": [128000, 8157, 326, 69581, 2795, 430, 994, 568, 15243, 311, 813, 10003, 1364, 1047, 539, 35661, 304, 8223, 2919, 323, 574, 5115, 30056, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23]]}, {\"piece_ids\": [128000, 14724, 5038, 14238, 420, 482, 482, 4587, 3136, 311, 3350, 311, 603, 13, 128001], \"label\": [9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[3, 3], [10, 10], [1, 1], [2, 2], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [11, 11], [12, 12], [13, 13]]}, {\"piece_ids\": [128000, 48561, 83824, 11, 889, 574, 8223, 4038, 20895, 11, 1047, 6931, 1027, 7556, 449, 1077, 6691, 389, 279, 4641, 11, 323, 18799, 709, 5605, 264, 5333, 1364, 1047, 523, 12400, 449, 2930, 1047, 1120, 11721, 520, 1077, 6134, 11, 11527, 1071, 13, 128001], \"label\": [9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[19, 19], [29, 30], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42]]}, {\"piece_ids\": [128000, 72, 1781, 584, 1253, 617, 15243, 1603, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8]]}, {\"piece_ids\": [128000, 84, 13, 274, 13, 9232, 19607, 1541, 4852, 305, 13, 436, 6370, 31202, 14407, 279, 11175, 449, 10461, 13015, 259, 3633, 1529, 1334, 323, 9232, 19607, 3980, 1885, 305, 9186, 389, 80413, 439, 436, 6370, 31202, 6052, 505, 264, 7364, 315, 6348, 37406, 11, 8136, 16083, 9121, 323, 279, 7565, 1122, 342, 14643, 5654, 13, 128001], \"label\": [9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[14, 14], [37, 37], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55]]}, {\"piece_ids\": [128000, 72, 656, 539, 1781, 430, 596, 5115, 13687, 439, 311, 1148, 568, 6267, 757, 922, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[13, 13], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [14, 14], [15, 15], [16, 16]]}, {\"piece_ids\": [128000, 11998, 261, 551, 20673, 648, 374, 539, 279, 1193, 6411, 7555, 889, 4036, 264, 6685, 323, 6661, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[17, 17], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [18, 18]]}, {\"piece_ids\": [128000, 438, 9901, 499, 1633, 1790, 311, 701, 4236, 369, 682, 279, 1862, 323, 279, 12197, 430, 814, 3288, 704, 311, 603, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[15, 15], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22]]}, {\"piece_ids\": [128000, 6797, 94496, 13306, 45693, 13, 128001], \"label\": [9, 0, 0, 0, 0], \"span\": [[1, 1], [2, 2], [3, 3], [4, 4], [5, 5]]}, {\"piece_ids\": [128000, 72, 1781, 584, 1253, 617, 15243, 1603, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8]]}, {\"piece_ids\": [128000, 93057, 4934, 311, 1650, 13, 128001], \"label\": [9, 0, 0, 0, 0], \"span\": [[4, 4], [1, 1], [2, 2], [3, 3], [5, 5]]}, {\"piece_ids\": [128000, 9514, 649, 1297, 814, 527, 48309, 704, 889, 814, 1288, 617, 1650, 1828, 892, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[12, 12], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [13, 13], [14, 14], [15, 15]]}, {\"piece_ids\": [128000, 564, 7752, 11, 14931, 369, 279, 1317, 384, 482, 8232, 323, 279, 18302, 9894, 11, 719, 602, 1390, 311, 1304, 2771, 430, 602, 617, 4395, 9960, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 10], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27]]}, {\"piece_ids\": [128000, 275, 690, 617, 311, 387, 4224, 607, 8232, 482, 436, 10910, 87022, 3041, 1077, 264, 1650, 520, 279, 4219, 11, 477, 3708, 1077, 264, 49719, 323, 10788, 1077, 311, 1057, 4219, 13, 128001], \"label\": [9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[16, 16], [25, 25], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32]]}, {\"piece_ids\": [128000, 275, 596, 2288, 3958, 1884, 912, 5418, 1274, 1047, 539, 1511, 279, 21186, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[11, 11], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [12, 12], [13, 13], [14, 14]]}, {\"piece_ids\": [128000, 15357, 505, 3453, 424, 11, 1933, 2172, 14238, 11, 1595, 1595, 68111, 11, 499, 2567, 57616, 14321, 86298, 783, 11486, 7241, 311, 6348, 37406, 4708, 482, 482, 902, 602, 656, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31]]}, {\"piece_ids\": [128000, 906, 1373, 682, 315, 701, 384, 482, 8232, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0], \"span\": [[6, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [9, 9]]}, {\"piece_ids\": [128000, 275, 596, 2288, 3958, 1884, 912, 5418, 1274, 1047, 539, 1511, 279, 21186, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[11, 11], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [12, 12], [13, 13], [14, 14]]}, {\"piece_ids\": [128000, 13486, 1578, 11, 584, 2351, 4560, 311, 636, 264, 6416, 315, 1057, 98769, 305, 12930, 11, 889, 574, 1120, 449, 603, 389, 279, 4641, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[24, 24], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [25, 25]]}, {\"piece_ids\": [128000, 20670, 3358, 1101, 387, 4737, 701, 4641, 6880, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9]]}, {\"piece_ids\": [128000, 9210, 596, 3460, 315, 19018, 304, 1521, 6880, 11, 304, 856, 3217, 779, 3117, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15]]}, {\"piece_ids\": [128000, 564, 7752, 11, 14931, 369, 279, 1317, 384, 482, 8232, 323, 279, 18302, 9894, 11, 719, 602, 1390, 311, 1304, 2771, 430, 602, 617, 4395, 9960, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 10], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27]]}, {\"piece_ids\": [128000, 12, 326, 10910, 482, 7899, 482, 927, 482, 436, 10910, 482, 551, 719, 4315, 279, 32731, 11, 16766, 11, 28608, 11, 4538, 277, 323, 17320, 11, 584, 1766, 264, 6367, 10500, 8621, 389, 279, 3185, 315, 279, 16006, 430, 17482, 439, 279, 3290, 4219, 551, 12197, 505, 2132, 482, 6117, 388, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[46, 46], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [47, 47], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52]]}, {\"piece_ids\": [128000, 54719, 12197, 3062, 520, 2225, 10548, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0], \"span\": [[2, 2], [1, 1], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7]]}, {\"piece_ids\": [128000, 72, 574, 389, 279, 4641, 449, 24154, 6853, 690, 12663, 13985, 11, 994, 1364, 5602, 1884, 1176, 9364, 389, 61558, 315, 1077, 10177, 11, 323, 1364, 48494, 291, 449, 18454, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31]]}, {\"piece_ids\": [128000, 72, 617, 539, 4036, 8232, 304, 1403, 2919, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9]]}, {\"piece_ids\": [128000, 9514, 649, 384, 482, 8232, 603, 482, 482, 420, 2884, 1797, 11, 14931, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[3, 5], [1, 1], [2, 2], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14]]}, {\"piece_ids\": [128000, 19171, 11, 1095, 757, 1440, 889, 499, 617, 2736, 25559, 323, 743, 709, 264, 6574, 449, 779, 430, 602, 649, 1304, 2771, 584, 656, 539, 1650, 1124, 11157, 13, 128001], \"label\": [4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[15, 15], [26, 26], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [27, 27], [28, 28], [29, 29]]}, {\"piece_ids\": [128000, 564, 7752, 11, 14931, 369, 279, 1317, 384, 482, 8232, 323, 279, 18302, 9894, 11, 719, 602, 1390, 311, 1304, 2771, 430, 602, 617, 4395, 9960, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 10], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27]]}, {\"piece_ids\": [128000, 28753, 18570, 1047, 482, 482, 2663, 279, 3754, 1274, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10]]}, {\"piece_ids\": [128000, 6797, 94496, 13306, 45693, 13, 128001], \"label\": [9, 0, 0, 0, 0], \"span\": [[1, 1], [2, 2], [3, 3], [4, 4], [5, 5]]}, {\"piece_ids\": [128000, 32158, 6944, 311, 1650, 1077, 20895, 10003, 274, 12273, 482, 326, 10910, 482, 1343, 482, 436, 10910, 482, 304, 2064, 14466, 311, 1518, 422, 1364, 706, 12886, 13, 128001], \"label\": [9, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 4], [27, 27], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [28, 28]]}, {\"piece_ids\": [128000, 93057, 4934, 311, 1650, 13, 128001], \"label\": [9, 0, 0, 0, 0], \"span\": [[4, 4], [1, 1], [2, 2], [3, 3], [5, 5]]}, {\"piece_ids\": [128000, 48561, 83824, 11, 889, 574, 8223, 4038, 20895, 11, 1047, 6931, 1027, 7556, 449, 1077, 6691, 389, 279, 4641, 11, 323, 18799, 709, 5605, 264, 5333, 1364, 1047, 523, 12400, 449, 2930, 1047, 1120, 11721, 520, 1077, 6134, 11, 11527, 1071, 13, 128001], \"label\": [9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[19, 19], [29, 30], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42]]}, {\"piece_ids\": [128000, 11998, 261, 551, 1243, 279, 8945, 596, 6691, 1903, 264, 89706, 1650, 311, 4379, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[12, 12], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [13, 13], [14, 14], [15, 15]]}, {\"piece_ids\": [128000, 84, 13, 274, 13, 14065, 39034, 62281, 1071, 20605, 39330, 25559, 357, 258, 83824, 1555, 459, 2930, 1984, 4580, 11, 323, 11527, 7315, 291, 304, 389, 1077, 1701, 6500, 2291, 4511, 1233, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[11, 11], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33]]}, {\"piece_ids\": [128000, 67971, 4918, 12886, 279, 12197, 311, 10687, 2737, 45381, 11, 84599, 323, 279, 6278, 11226, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[3, 3], [1, 1], [2, 2], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16]]}, {\"piece_ids\": [128000, 576, 11714, 11, 922, 220, 23, 551, 220, 1774, 281, 13, 296, 2637, 3697, 315, 856, 49184, 3486, 5089, 4036, 264, 21186, 1650, 505, 459, 6179, 83, 535, 5605, 814, 3463, 430, 814, 1047, 13468, 279, 15562, 294, 61500, 83044, 304, 279, 3158, 315, 33633, 6678, 323, 1541, 4852, 83044, 65764, 6246, 3195, 304, 54085, 71554, 8424, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[23, 23], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55], [56, 56], [57, 57], [58, 58]]}, {\"piece_ids\": [128000, 72, 3197, 311, 1650, 1077, 420, 6693, 323, 3371, 1077, 279, 2860, 11, 4686, 449, 856, 19160, 1841, 369, 264, 2046, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 4], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22]]}, {\"piece_ids\": [128000, 383, 3288, 3892, 12197, 311, 279, 4379, 323, 279, 3772, 2391, 430, 892, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 4], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14]]}, {\"piece_ids\": [128000, 13486, 1578, 11, 584, 2351, 4560, 311, 636, 264, 6416, 315, 1057, 98769, 305, 12930, 11, 889, 574, 1120, 449, 603, 389, 279, 4641, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[24, 24], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [25, 25]]}, {\"piece_ids\": [128000, 1712, 1457, 369, 1595, 1595, 4027, 1445, 41610, 1405, 1057, 289, 81057, 323, 597, 67824, 7359, 323, 4885, 323, 23531, 1314, 304, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[21, 21], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [22, 22], [23, 23]]}, {\"piece_ids\": [128000, 23770, 499, 1440, 430, 832, 315, 279, 7928, 3772, 5220, 304, 279, 3224, 574, 304, 279, 2626, 315, 12967, 499, 1595, 1595, 5054, 586, 2532, 6743, 30, 4708, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[26, 26], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [27, 27], [28, 28]]}, {\"piece_ids\": [128000, 32158, 6944, 311, 1650, 1077, 20895, 10003, 274, 12273, 482, 326, 10910, 482, 1343, 482, 436, 10910, 482, 304, 2064, 14466, 311, 1518, 422, 1364, 706, 12886, 13, 128001], \"label\": [9, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 4], [27, 27], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [28, 28]]}, {\"piece_ids\": [128000, 11998, 261, 551, 20673, 648, 374, 539, 279, 1193, 6411, 7555, 889, 4036, 264, 6685, 323, 6661, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[17, 17], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [18, 18]]}, {\"piece_ids\": [128000, 72, 656, 539, 1781, 430, 596, 5115, 13687, 439, 311, 1148, 568, 6267, 757, 922, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[13, 13], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [14, 14], [15, 15], [16, 16]]}, {\"piece_ids\": [128000, 906, 1373, 682, 315, 701, 384, 482, 8232, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0], \"span\": [[6, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [9, 9]]}, {\"piece_ids\": [128000, 383, 3288, 3892, 12197, 311, 279, 4379, 323, 279, 3772, 2391, 430, 892, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 4], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14]]}, {\"piece_ids\": [128000, 258, 813, 3766, 6661, 2162, 11, 74506, 18178, 94441, 1437, 96274, 1550, 539, 3371, 813, 3070, 279, 2539, 3649, 922, 813, 1176, 12896, 9131, 13, 128001], \"label\": [1, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[23, 23], [14, 14], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [24, 24], [25, 25]]}, {\"piece_ids\": [128000, 72, 617, 539, 4036, 8232, 304, 1403, 2919, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9]]}, {\"piece_ids\": [128000, 275, 596, 2288, 3958, 1884, 912, 5418, 1274, 1047, 539, 1511, 279, 21186, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[11, 11], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [12, 12], [13, 13], [14, 14]]}, {\"piece_ids\": [128000, 65, 710, 3258, 5762, 709, 264, 5729, 315, 810, 1109, 220, 4728, 384, 482, 86658, 505, 70240, 307, 5493, 889, 568, 1071, 617, 5439, 1461, 311, 1862, 279, 4121, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[24, 24], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30]]}, {\"piece_ids\": [128000, 15031, 577, 13, 274, 13, 17312, 617, 539, 1047, 264, 6140, 311, 1650, 2162, 2533, 814, 1051, 27167, 369, 14523, 304, 1595, 1595, 5784, 6348, 37406, 72, 11542, 43584, 128001], \"label\": [9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[13, 13], [18, 18], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [14, 14], [15, 15], [16, 16], [17, 17], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29]]}, {\"piece_ids\": [128000, 383, 29782, 603, 1457, 505, 94771, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0], \"span\": [[2, 2], [1, 1], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7]]}, {\"piece_ids\": [128000, 72, 574, 389, 279, 4641, 449, 24154, 6853, 690, 12663, 13985, 11, 994, 1364, 5602, 1884, 1176, 9364, 389, 61558, 315, 1077, 10177, 11, 323, 1364, 48494, 291, 449, 18454, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31]]}, {\"piece_ids\": [128000, 1964, 2132, 482, 6117, 388, 1051, 1633, 8173, 304, 11889, 1063, 12197, 704, 311, 279, 17312, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[12, 12], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17]]}, {\"piece_ids\": [128000, 66, 7521, 9687, 279, 453, 2874, 35760, 7808, 3288, 4443, 12197, 311, 1401, 73290, 304, 1172, 6955, 11, 22106, 1124, 311, 3440, 279, 29292, 5415, 323, 1202, 20724, 13, 128001], \"label\": [9, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[9, 9], [22, 22], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29]]}, {\"piece_ids\": [128000, 93375, 8336, 2019, 279, 44818, 3782, 505, 279, 3973, 1990, 87098, 323, 8136, 16083, 9121, 11, 1405, 2709, 3105, 9736, 82787, 374, 11846, 311, 387, 26092, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27]]}, {\"piece_ids\": [128000, 2201, 18084, 11, 912, 384, 482, 8232, 11, 12197, 527, 279, 1193, 2723, 311, 2162, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[9, 9], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16]]}, {\"piece_ids\": [128000, 1820, 3117, 66, 16495, 279, 9473, 315, 810, 1109, 220, 2031, 19287, 11, 15201, 323, 86219, 304, 1202, 2585, 369, 7154, 220, 2636, 36723, 52942, 555, 279, 3109, 11, 1071, 326, 9425, 3567, 689, 11, 1101, 3967, 439, 436, 5049, 312, 9891, 11, 264, 3117, 66, 7808, 11, 304, 264, 6661, 3288, 311, 279, 2068, 96701, 24840, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[51, 51], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50], [52, 52], [53, 53], [54, 54], [55, 55], [56, 56], [57, 57], [58, 58]]}, {\"piece_ids\": [128000, 65, 710, 3258, 5762, 709, 264, 5729, 315, 810, 1109, 220, 4728, 384, 482, 86658, 505, 70240, 307, 5493, 889, 568, 1071, 617, 5439, 1461, 311, 1862, 279, 4121, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[24, 24], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30]]}, {\"piece_ids\": [128000, 48561, 83824, 11, 889, 574, 8223, 4038, 20895, 11, 1047, 6931, 1027, 7556, 449, 1077, 6691, 389, 279, 4641, 11, 323, 18799, 709, 5605, 264, 5333, 1364, 1047, 523, 12400, 449, 2930, 1047, 1120, 11721, 520, 1077, 6134, 11, 11527, 1071, 13, 128001], \"label\": [9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[19, 19], [29, 30], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42]]}, {\"piece_ids\": [128000, 48561, 83824, 11, 889, 574, 8223, 4038, 20895, 11, 1047, 6931, 1027, 7556, 449, 1077, 6691, 389, 279, 4641, 11, 323, 18799, 709, 5605, 264, 5333, 1364, 1047, 523, 12400, 449, 2930, 1047, 1120, 11721, 520, 1077, 6134, 11, 11527, 1071, 13, 128001], \"label\": [9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[19, 19], [29, 30], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42]]}, {\"piece_ids\": [128000, 72, 482, 482, 602, 2846, 8260, 499, 505, 502, 50672, 3363, 11, 68111, 11, 433, 596, 264, 17069, 311, 3449, 499, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22]]}, {\"piece_ids\": [128000, 72, 656, 539, 1781, 430, 596, 5115, 13687, 439, 311, 1148, 568, 6267, 757, 922, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[13, 13], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [14, 14], [15, 15], [16, 16]]}, {\"piece_ids\": [128000, 543, 279, 15051, 1051, 15687, 889, 1047, 2322, 279, 42447, 323, 40941, 482, 326, 10910, 482, 459, 19411, 3995, 5743, 889, 1051, 51129, 7636, 482, 436, 10910, 482, 21907, 389, 60197, 762, 50308, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34]]}, {\"piece_ids\": [128000, 72, 2846, 75477, 42365, 323, 7556, 389, 279, 4641, 1418, 4477, 420, 5296, 43584, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14]]}, {\"piece_ids\": [128000, 285, 430, 482, 482, 374, 430, 279, 832, 1405, 18570, 2663, 264, 3754, 482, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[11, 11], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [12, 12], [13, 13], [14, 14]]}, {\"piece_ids\": [128000, 20670, 15243, 555, 23895, 78303, 420, 6693, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0], \"span\": [[2, 2], [1, 1], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8]]}, {\"piece_ids\": [128000, 906, 3021, 11011, 505, 499, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0], \"span\": [[3, 3], [1, 1], [2, 2], [4, 4], [5, 5], [6, 6]]}, {\"piece_ids\": [128000, 3556, 1364, 574, 389, 279, 4641, 11, 568, 13061, 709, 279, 1716, 1578, 323, 420, 892, 22982, 1077, 704, 279, 3321, 13, 128001], \"label\": [2, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[17, 17], [5, 6], [1, 1], [2, 2], [3, 3], [4, 4], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22]]}, {\"piece_ids\": [128000, 9514, 649, 1297, 814, 527, 48309, 704, 889, 814, 1288, 617, 1650, 1828, 892, 13, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[12, 12], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [13, 13], [14, 14], [15, 15]]}, {\"piece_ids\": [128000, 72, 2846, 75477, 42365, 323, 7556, 389, 279, 4641, 1418, 4477, 420, 5296, 43584, 128001], \"label\": [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14]]}], \"2\": [{\"piece_ids\": [128000, 20670, 32122, 311, 513, 11206, 389, 93463, 311, 10015, 10007, 597, 46295, 7510, 389, 872, 18671, 8577, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[17, 17], [2, 2], [1, 1], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [18, 18]]}, {\"piece_ids\": [128000, 1820, 13695, 596, 220, 11908, 6634, 70863, 84972, 11, 2737, 21342, 13695, 436, 14381, 11, 27096, 704, 315, 3428, 482, 16706, 272, 482, 220, 1114, 7710, 25761, 1234, 3504, 315, 27394, 11077, 7465, 323, 27528, 264, 12056, 482, 16174, 291, 3805, 2630, 11, 902, 690, 387, 1511, 311, 4546, 304, 17135, 323, 1862, 17274, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[16, 16], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55]]}, {\"piece_ids\": [128000, 74946, 311, 1023, 6821, 19261, 1618, 11, 4330, 6705, 7414, 5951, 22961, 1051, 7577, 323, 220, 605, 3885, 1051, 15902, 389, 93463, 6693, 994, 264, 603, 26290, 4295, 279, 5951, 814, 1051, 21646, 304, 3221, 279, 6348, 37406, 72, 3973, 13, 128001], \"label\": [3, 2, 8, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[14, 14], [33, 33], [20, 20], [28, 28], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [29, 29], [30, 30], [31, 31], [32, 32], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41]]}, {\"piece_ids\": [128000, 438, 1148, 584, 2351, 9455, 1457, 374, 430, 279, 13147, 12295, 527, 15676, 11, 30988, 19169, 527, 15676, 11, 20895, 3278, 2211, 539, 1505, 264, 10896, 311, 6493, 279, 8945, 11, 264, 8334, 33085, 40711, 706, 311, 387, 40460, 311, 2500, 1614, 13, 128001], \"label\": [23, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[18, 18], [34, 34], [39, 39], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [35, 35], [36, 36], [37, 37], [38, 38], [40, 40], [41, 41], [42, 42], [43, 43]]}, {\"piece_ids\": [128000, 906, 2351, 2133, 927, 1070, 11, 584, 2351, 5605, 11, 1427, 11, 420, 374, 1268, 584, 656, 433, 482, 482, 323, 11, 4543, 11, 602, 482, 482, 482, 779, 584, 1781, 16470, 775, 1288, 387, 430, 1648, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[3, 3], [1, 1], [2, 2], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38]]}, {\"piece_ids\": [128000, 28226, 3633, 3678, 19549, 574, 12502, 1120, 264, 2305, 1603, 1364, 2163, 369, 6348, 37406, 13, 128001], \"label\": [16, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [12, 12], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [13, 13], [14, 14], [15, 15], [16, 16]]}, {\"piece_ids\": [128000, 66467, 798, 706, 1071, 433, 1253, 3708, 810, 17312, 1139, 18671, 6348, 37406, 311, 5471, 22475, 505, 7366, 10411, 11, 1418, 577, 13, 274, 13, 7510, 617, 1071, 814, 26160, 45405, 2403, 11889, 3544, 5217, 8603, 1139, 18671, 6348, 37406, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[7, 7], [33, 33], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41]]}, {\"piece_ids\": [128000, 300, 584, 15746, 420, 6945, 315, 279, 3805, 5457, 832, 3794, 1139, 420, 17149, 602, 1390, 311, 4546, 304, 1057, 6411, 18738, 4689, 9279, 60053, 1543, 311, 733, 927, 1148, 8741, 12765, 304, 9145, 16373, 329, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[11, 12], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37]]}, {\"piece_ids\": [128000, 455, 1828, 11, 264, 1934, 389, 279, 4872, 596, 8577, 311, 3190, 514, 3841, 2957, 11, 323, 264, 1427, 520, 1268, 279, 3190, 514, 3841, 2957, 4029, 374, 63082, 449, 279, 11774, 315, 4208, 13, 128001], \"label\": [2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[10, 10], [34, 34], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [35, 35]]}, {\"piece_ids\": [128000, 1820, 308, 15790, 323, 279, 87019, 3634, 9266, 2225, 7195, 25664, 311, 48449, 420, 2305, 11889, 938, 3078, 323, 439, 427, 388, 311, 22477, 279, 2579, 11841, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[16, 16], [11, 11], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [12, 12], [13, 13], [14, 14], [15, 15], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28]]}, {\"piece_ids\": [128000, 27295, 5101, 311, 1501, 430, 220, 2636, 410, 721, 3026, 721, 1051, 23959, 315, 53451, 2391, 279, 308, 18291, 6037, 11, 9455, 704, 1268, 1690, 1051, 3288, 311, 264, 3190, 323, 7577, 1070, 374, 810, 5107, 5423, 439, 1063, 889, 1051, 3288, 311, 4725, 99665, 1051, 23217, 311, 29135, 520, 279, 842, 315, 872, 11914, 11, 719, 220, 605, 482, 220, 868, 74, 5084, 13579, 128001], \"label\": [18, 2, 3, 2, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[13, 13], [27, 27], [32, 32], [47, 47], [55, 55], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [28, 28], [29, 29], [30, 30], [31, 31], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [56, 56], [57, 57], [58, 58], [59, 59], [60, 60], [61, 61], [62, 62], [63, 63], [64, 64], [65, 65]]}, {\"piece_ids\": [128000, 631, 258, 323, 813, 7555, 2163, 369, 279, 4033, 23991, 430, 499, 2351, 9298, 1457, 1618, 304, 8792, 63146, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20]]}, {\"piece_ids\": [128000, 22491, 616, 374, 42295, 709, 264, 8577, 311, 42552, 84599, 11, 568, 596, 4245, 1618, 304, 21706, 25245, 16986, 6693, 369, 13739, 449, 279, 374, 6327, 72, 10461, 13015, 323, 279, 7362, 13015, 13, 128001], \"label\": [2, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[7, 7], [14, 14], [22, 22], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34]]}, {\"piece_ids\": [128000, 31372, 26283, 15201, 7366, 9017, 264, 348, 10766, 51112, 520, 279, 1715, 315, 264, 62056, 92658, 11, 719, 19021, 25958, 889, 1550, 539, 3619, 1148, 814, 1051, 4560, 311, 656, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 5], [1, 1], [2, 2], [3, 3], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31]]}, {\"piece_ids\": [128000, 9336, 11, 279, 23855, 1274, 482, 482, 602, 8101, 11, 814, 1205, 872, 12185, 7558, 11, 779, 814, 3169, 315, 4024, 18403, 11, 779, 482, 482, 4543, 482, 482, 602, 3152, 433, 596, 264, 2678, 3245, 11, 719, 433, 574, 11, 814, 1120, 25720, 704, 11, 814, 1051, 482, 482, 499, 1440, 11, 44844, 482, 482, 6975, 505, 3217, 389, 1148, 814, 1205, 311, 656, 304, 279, 482, 482, 3363, 323, 482, 482, 602, 1781, 568, 1053, 387, 264, 1695, 482, 482, 9322, 369, 279, 56336, 4868, 11, 4401, 430, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[21, 21], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55], [56, 56], [57, 57], [58, 58], [59, 59], [60, 60], [61, 61], [62, 62], [63, 63], [64, 64], [65, 65], [66, 66], [67, 67], [68, 68], [69, 69], [70, 70], [71, 71], [72, 72], [73, 73], [74, 74], [75, 75], [76, 76], [77, 77], [78, 78], [79, 79], [80, 80], [81, 81], [82, 82], [83, 83], [84, 84], [85, 85], [86, 86], [87, 87], [88, 88], [89, 89], [90, 90], [91, 91]]}, {\"piece_ids\": [128000, 66, 3806, 2019, 568, 19755, 55945, 1077, 304, 813, 1841, 323, 21699, 1077, 719, 9778, 7263, 1077, 1203, 311, 1077, 2162, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[16, 16], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22]]}, {\"piece_ids\": [128000, 9336, 11, 433, 374, 1057, 2543, 311, 3449, 279, 597, 2453, 388, 1203, 304, 279, 577, 13, 274, 13, 1306, 872, 11879, 311, 33625, 311, 4546, 2162, 279, 24519, 323, 4018, 478, 8530, 11, 4562, 315, 872, 3070, 11, 304, 2537, 33275, 645, 11, 279, 12691, 6699, 315, 220, 806, 29038, 339, 671, 85306, 597, 47469, 13, 128001], \"label\": [2, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[22, 22], [26, 26], [8, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [23, 23], [24, 24], [25, 25], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55], [56, 56], [57, 57]]}, {\"piece_ids\": [128000, 20670, 2351, 14836, 311, 934, 6258, 94441, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0], \"span\": [[3, 3], [1, 1], [2, 2], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8]]}, {\"piece_ids\": [128000, 383, 482, 482, 1306, 20948, 323, 4737, 264, 10015, 7364, 315, 961, 315, 279, 8448, 11, 568, 1101, 4024, 704, 389, 311, 279, 11213, 9722, 323, 13468, 1063, 315, 279, 11213, 7677, 315, 1063, 315, 279, 282, 482, 220, 972, 14467, 430, 527, 1457, 9564, 1521, 14467, 11, 19946, 311, 32703, 461, 1306, 420, 220, 605, 482, 2305, 1317, 10739, 1097, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[49, 49], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55], [56, 56], [57, 57], [58, 58], [59, 59], [60, 60], [61, 61], [62, 62]]}, {\"piece_ids\": [128000, 98936, 11, 279, 1403, 35991, 10565, 704, 315, 70723, 520, 279, 4545, 1051, 3288, 9909, 449, 3177, 6286, 11, 389, 11000, 32896, 287, 11543, 449, 279, 72961, 77, 597, 5362, 719, 2192, 11, 902, 1047, 3117, 810, 35991, 323, 264, 3117, 44922, 6286, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[14, 14], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44]]}, {\"piece_ids\": [128000, 606, 315, 279, 2466, 4860, 922, 48449, 374, 994, 477, 3508, 12966, 690, 3596, 387, 3025, 311, 4034, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[18, 18], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [19, 19]]}, {\"piece_ids\": [128000, 1820, 13695, 596, 220, 18, 6634, 55527, 706, 62018, 1555, 24318, 65, 6181, 11, 6574, 1193, 3177, 13957, 505, 279, 1812, 2259, 91536, 7771, 11, 323, 7366, 3235, 27834, 11888, 2949, 220, 914, 8931, 315, 9145, 16373, 329, 13, 128001], \"label\": [2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[9, 9], [18, 18], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39]]}, {\"piece_ids\": [128000, 72, 1120, 1781, 922, 682, 279, 3070, 3697, 11961, 520, 2162, 11, 11961, 389, 279, 28649, 3411, 520, 420, 15688, 5108, 304, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[21, 21], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [22, 22], [23, 23]]}, {\"piece_ids\": [128000, 300, 584, 15746, 420, 6945, 315, 279, 3805, 5457, 832, 3794, 1139, 420, 17149, 602, 1390, 311, 4546, 304, 1057, 6411, 18738, 4689, 9279, 60053, 1543, 311, 733, 927, 1148, 8741, 12765, 304, 9145, 16373, 329, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[11, 12], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37]]}, {\"piece_ids\": [128000, 86667, 26140, 574, 279, 1176, 1948, 6348, 37406, 72, 14076, 7808, 311, 387, 83757, 2130, 291, 555, 279, 577, 13, 274, 13, 6411, 1139, 18561, 6348, 37406, 439, 279, 11039, 27653, 1523, 11, 323, 568, 323, 1023, 1948, 3697, 315, 813, 1912, 3197, 311, 3449, 5246, 304, 9145, 16373, 329, 13, 128001], \"label\": [1, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[30, 30], [14, 16], [45, 45], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50], [51, 51]]}, {\"piece_ids\": [128000, 275, 15812, 1120, 220, 717, 8931, 505, 9145, 16373, 329, 323, 690, 387, 264, 1401, 4741, 2385, 369, 577, 13, 274, 13, 17312, 439, 814, 10772, 369, 264, 4585, 389, 279, 6864, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[29, 29], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [30, 30], [31, 31], [32, 32], [33, 33]]}, {\"piece_ids\": [128000, 3768, 276, 574, 7882, 555, 279, 3109, 311, 1202, 46567, 24549, 304, 50332, 7911, 11, 1405, 568, 574, 17439, 555, 13535, 74720, 3290, 437, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 4], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25]]}, {\"piece_ids\": [128000, 708, 1148, 596, 279, 17250, 304, 1694, 3025, 311, 733, 311, 48449, 30, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[10, 10], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [11, 11], [12, 12], [13, 13]]}, {\"piece_ids\": [128000, 9514, 2351, 11890, 757, 4423, 574, 3025, 311, 1935, 459, 17774, 482, 220, 2618, 1595, 1595, 11965, 29232, 4708, 1139, 264, 34353, 323, 5934, 554, 1274, 27074, 128001], \"label\": [8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[24, 25], [9, 9], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [26, 26], [27, 27]]}, {\"piece_ids\": [128000, 15031, 13695, 8316, 73317, 6348, 37406, 72, 24080, 505, 264, 91536, 7771, 26097, 4871, 279, 6864, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 4], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17]]}, {\"piece_ids\": [128000, 9210, 596, 279, 1193, 555, 6634, 36167, 2447, 602, 617, 3596, 12263, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[12, 12], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [13, 13]]}, {\"piece_ids\": [128000, 64, 27626, 11, 503, 434, 3074, 326, 69581, 5108, 1203, 311, 279, 29292, 5415, 2949, 279, 6596, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[9, 9], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18]]}, {\"piece_ids\": [128000, 906, 527, 539, 23132, 311, 6678, 1139, 9145, 16373, 329, 15187, 323, 51085, 433, 304, 264, 16081, 409, 69236, 11, 477, 4205, 1093, 430, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25]]}, {\"piece_ids\": [128000, 20670, 7882, 279, 27202, 311, 264, 1812, 54803, 7458, 4669, 1403, 482, 893, 39682, 6920, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[2, 2], [1, 1], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16]]}, {\"piece_ids\": [128000, 94323, 95146, 11, 8040, 24392, 369, 6411, 10096, 11, 1051, 9277, 520, 96862, 596, 2609, 72, 17149, 1566, 2046, 311, 1817, 1274, 33111, 505, 274, 1590, 482, 11754, 5961, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[23, 23], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30]]}, {\"piece_ids\": [128000, 1820, 893, 574, 12800, 1070, 1306, 11527, 2019, 568, 22130, 11440, 264, 19250, 276, 11277, 1701, 1148, 574, 5068, 311, 387, 80059, 11, 22106, 279, 36377, 311, 11722, 311, 76754, 13, 128001], \"label\": [2, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[28, 28], [4, 4], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [29, 29], [30, 30], [31, 31]]}, {\"piece_ids\": [128000, 72, 656, 539, 1440, 922, 279, 2800, 315, 499, 719, 602, 1781, 430, 304, 279, 1828, 2478, 5672, 602, 690, 387, 7366, 17135, 323, 7241, 311, 856, 2816, 304, 24024, 297, 17541, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[22, 22], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33]]}, {\"piece_ids\": [128000, 383, 574, 3288, 927, 1314, 1828, 311, 279, 7565, 1122, 342, 14643, 1457, 2533, 502, 1060, 596, 49996, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[3, 3], [1, 1], [2, 2], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19]]}, {\"piece_ids\": [128000, 12, 1664, 11, 856, 13219, 6118, 4131, 304, 505, 96985, 1606, 433, 596, 539, 430, 3117, 1093, 482, 482, 1403, 7895, 33517, 8931, 477, 2555, 11, 323, 1364, 3358, 2586, 304, 369, 9901, 32727, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[7, 7], [30, 30], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35]]}, {\"piece_ids\": [128000, 79, 1604, 48561, 5493, 323, 872, 62370, 819, 374, 6327, 72, 20724, 40076, 1005, 279, 3492, 1595, 1595, 30747, 4708, 994, 26192, 430, 374, 6327, 5387, 279, 9909, 6201, 323, 342, 12997, 323, 95158, 89238, 45704, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[26, 26], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37]]}, {\"piece_ids\": [128000, 59961, 527, 1523, 311, 220, 1135, 3346, 11, 719, 1070, 596, 2103, 832, 477, 1403, 37601, 2212, 220, 2075, 11, 220, 1490, 11, 220, 1954, 3346, 315, 872, 11039, 8333, 11, 323, 814, 1436, 2103, 2231, 709, 1633, 31161, 13957, 11, 13118, 11, 994, 279, 39542, 8603, 636, 665, 58617, 311, 9145, 16373, 329, 5196, 13, 128001], \"label\": [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[29, 29], [48, 48], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55], [56, 56]]}, {\"piece_ids\": [128000, 11998, 261, 551, 279, 28497, 25664, 311, 19614, 369, 12195, 315, 2324, 527, 743, 369, 264, 11879, 315, 264, 8502, 7239, 8931, 11, 15691, 20086, 2579, 11841, 938, 3078, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[17, 17], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30]]}, {\"piece_ids\": [128000, 8781, 750, 279, 8792, 3290, 1071, 279, 21487, 39935, 3754, 8024, 574, 1694, 67331, 1606, 568, 44500, 279, 3813, 315, 279, 5089, 568, 596, 1027, 23711, 449, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[14, 14], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28]]}, {\"piece_ids\": [128000, 275, 574, 311, 3240, 279, 4848, 482, 6596, 11879, 1139, 4543, 76, 2874, 300, 81, 389, 11077, 7465, 11, 4184, 311, 264, 7463, 1934, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[9, 9], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25]]}, {\"piece_ids\": [128000, 20322, 69026, 6278, 5794, 11, 409, 781, 89, 2649, 40207, 323, 30010, 279, 3224, 389, 18998, 6048, 220, 1114, 11, 220, 1049, 18, 13, 128001], \"label\": [5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[10, 10], [12, 12], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [11, 11], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24]]}, {\"piece_ids\": [128000, 76515, 11, 323, 814, 272, 482, 279, 2586, 2162, 311, 4400, 1306, 342, 482, 682, 814, 3077, 8208, 1555, 814, 2586, 2162, 323, 814, 617, 4400, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 8], [21, 21], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27]]}, {\"piece_ids\": [128000, 64, 64245, 29839, 5308, 48739, 12504, 1124, 1022, 420, 6693, 1306, 89310, 14268, 520, 279, 27605, 287, 96678, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19]]}, {\"piece_ids\": [128000, 1820, 1274, 315, 87272, 1018, 527, 5605, 58272, 309, 596, 3070, 2163, 430, 3363, 2380, 2919, 4227, 11, 1664, 1603, 279, 66879, 598, 11721, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[12, 12], [24, 24], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [25, 25]]}, {\"piece_ids\": [128000, 10097, 560, 70474, 220, 1644, 75500, 20550, 889, 3782, 24767, 461, 270, 7329, 304, 18561, 993, 467, 37606, 459, 88204, 9988, 15688, 11, 2737, 3892, 20895, 3278, 323, 1023, 40386, 16066, 505, 9950, 1605, 91299, 11, 4379, 1071, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[9, 9], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39]]}, {\"piece_ids\": [128000, 10924, 1690, 4520, 21078, 11633, 1752, 389, 279, 2115, 11, 282, 36008, 574, 5616, 7108, 4669, 27277, 9211, 11, 7231, 264, 57949, 709, 311, 279, 13734, 389, 279, 1648, 704, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[15, 15], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31]]}, {\"piece_ids\": [128000, 26301, 879, 11277, 11721, 520, 568, 589, 654, 17149, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 4], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10]]}, {\"piece_ids\": [128000, 383, 2751, 389, 264, 11213, 311, 459, 83957, 3813, 11, 994, 20673, 648, 2751, 264, 2132, 4641, 1650, 505, 264, 11213, 65022, 13, 128001], \"label\": [2, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [18, 18], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23]]}, {\"piece_ids\": [128000, 72, 3077, 1027, 311, 701, 17104, 1614, 3131, 1603, 11, 1523, 304, 279, 305, 980, 388, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[3, 3], [1, 1], [2, 2], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17]]}, {\"piece_ids\": [128000, 9336, 11, 994, 814, 656, 5616, 3810, 9145, 16373, 329, 11, 577, 13, 274, 13, 323, 26283, 17312, 1436, 3663, 16036, 12896, 449, 279, 91536, 7771, 11, 1063, 315, 8884, 1253, 617, 50682, 1139, 279, 3363, 13, 128001], \"label\": [2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[7, 7], [22, 22], [33, 34], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [35, 35], [36, 36], [37, 37]]}, {\"piece_ids\": [128000, 1820, 8952, 14224, 7020, 430, 701, 4333, 574, 3515, 2010, 5435, 11, 323, 814, 75298, 12020, 1461, 555, 539, 11889, 1461, 311, 264, 8841, 26741, 11, 902, 5535, 279, 6671, 311, 636, 11201, 3156, 279, 1486, 1405, 568, 46671, 4423, 13, 128001], \"label\": [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[39, 39], [20, 20], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [40, 40], [41, 41]]}, {\"piece_ids\": [128000, 72, 1440, 430, 574, 1148, 7077, 449, 856, 1866, 6699, 11, 14090, 1606, 872, 5597, 311, 636, 12502, 323, 856, 7126, 596, 5597, 311, 5249, 279, 8993, 3782, 1633, 3345, 3871, 11, 323, 814, 1550, 539, 1390, 311, 3868, 279, 1060, 3156, 568, 1053, 387, 3025, 311, 3810, 279, 27850, 13, 128001], \"label\": [16, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[18, 18], [48, 48], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [49, 49], [50, 50], [51, 51]]}, {\"piece_ids\": [128000, 9514, 2643, 1390, 311, 6068, 1022, 279, 1841, 15038, 3221, 2579, 6201, 11, 477, 439, 5246, 439, 499, 17782, 304, 502, 50672, 11, 422, 279, 6068, 1022, 10405, 527, 539, 2288, 1790, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[19, 19], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33]]}, {\"piece_ids\": [128000, 2465, 6980, 11, 44844, 11, 6980, 323, 872, 6980, 2586, 11, 682, 719, 832, 315, 1124, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[10, 10], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17]]}, {\"piece_ids\": [128000, 83, 729, 315, 9214, 315, 3281, 275, 1088, 86064, 38473, 1456, 311, 3810, 993, 467, 38484, 1855, 1060, 555, 27736, 279, 60392, 788, 610, 1339, 315, 342, 85896, 311, 5662, 279, 18561, 51115, 477, 555, 51129, 53342, 311, 279, 649, 661, 30100, 704, 304, 279, 71554, 8322, 13, 128001], \"label\": [2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[20, 20], [36, 36], [13, 13], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48]]}, {\"piece_ids\": [128000, 1820, 893, 574, 12800, 1070, 1306, 11527, 2019, 568, 22130, 11440, 264, 19250, 276, 11277, 1701, 1148, 574, 5068, 311, 387, 80059, 11, 22106, 279, 36377, 311, 11722, 311, 76754, 13, 128001], \"label\": [2, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[28, 28], [4, 4], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [29, 29], [30, 30], [31, 31]]}, {\"piece_ids\": [128000, 275, 574, 279, 1176, 5089, 311, 5425, 279, 65043, 4171, 988, 15140, 323, 1243, 21004, 10411, 1637, 311, 2949, 220, 1399, 8931, 315, 9145, 16373, 329, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[7, 7], [15, 15], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27]]}, {\"piece_ids\": [128000, 27295, 5101, 311, 1501, 430, 220, 2636, 410, 721, 3026, 721, 1051, 23959, 315, 53451, 2391, 279, 308, 18291, 6037, 11, 9455, 704, 1268, 1690, 1051, 3288, 311, 264, 3190, 323, 7577, 1070, 374, 810, 5107, 5423, 439, 1063, 889, 1051, 3288, 311, 4725, 99665, 1051, 23217, 311, 29135, 520, 279, 842, 315, 872, 11914, 11, 719, 220, 605, 482, 220, 868, 74, 5084, 13579, 128001], \"label\": [18, 2, 3, 2, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[13, 13], [27, 27], [32, 32], [47, 47], [55, 55], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [28, 28], [29, 29], [30, 30], [31, 31], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [56, 56], [57, 57], [58, 58], [59, 59], [60, 60], [61, 61], [62, 62], [63, 63], [64, 64], [65, 65]]}, {\"piece_ids\": [128000, 998, 1906, 813, 18526, 26438, 311, 279, 1948, 315, 12232, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11]]}, {\"piece_ids\": [128000, 64, 64245, 29839, 5308, 48739, 12504, 1124, 1022, 420, 6693, 1306, 89310, 14268, 520, 279, 27605, 287, 96678, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19]]}, {\"piece_ids\": [128000, 32414, 819, 24521, 32510, 4024, 1139, 279, 3363, 315, 220, 16, 13, 220, 18, 3610, 449, 810, 1109, 2380, 21030, 26951, 323, 65745, 9515, 11, 264, 3330, 4528, 304, 1404, 311, 279, 39542, 5089, 430, 463, 2788, 46318, 9145, 16373, 329, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 5], [36, 37], [1, 1], [2, 2], [3, 3], [4, 4], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42]]}, {\"piece_ids\": [128000, 258, 2144, 11, 584, 1120, 2751, 1203, 505, 834, 3520, 1917, 11, 499, 1440, 11, 922, 459, 6596, 4227, 323, 814, 2351, 1523, 1070, 323, 814, 2351, 719, 814, 2351, 2225, 11, 44844, 11, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 7], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34]]}, {\"piece_ids\": [128000, 258, 5369, 311, 430, 11, 584, 1440, 430, 4726, 1203, 4920, 1884, 5238, 304, 279, 5216, 315, 23518, 360, 1070, 374, 8987, 54235, 323, 26951, 439, 1664, 11, 420, 4184, 311, 279, 1274, 1618, 304, 420, 3158, 11, 279, 2254, 28364, 5469, 889, 617, 1027, 2133, 4028, 279, 5238, 369, 1690, 1667, 13524, 17045, 304, 74034, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[46, 47], [56, 56], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55], [57, 57]]}, {\"piece_ids\": [128000, 9336, 11, 439, 39542, 8603, 656, 4585, 8469, 9017, 279, 6348, 37406, 72, 3109, 596, 1401, 4219, 315, 2410, 11, 95027, 8603, 527, 10494, 709, 872, 990, 311, 279, 10007, 315, 279, 6348, 37406, 72, 6864, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[7, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37]]}, {\"piece_ids\": [128000, 1820, 54205, 315, 95076, 430, 1364, 8667, 5042, 3445, 430, 422, 1364, 92620, 704, 323, 5900, 311, 2500, 1614, 11, 1364, 2211, 539, 14130, 279, 1314, 315, 279, 4113, 5590, 311, 617, 1077, 305, 75767, 1203, 311, 1202, 29101, 11, 323, 430, 279, 5590, 24670, 539, 617, 311, 39201, 279, 892, 482, 35208, 1920, 315, 67902, 5977, 1077, 13, 128001], \"label\": [2, 2, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[13, 13], [34, 36], [4, 4], [56, 57], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55], [58, 58], [59, 59]]}, {\"piece_ids\": [128000, 906, 48248, 304, 264, 5030, 315, 14269, 11, 279, 19607, 315, 9232, 11, 1541, 4852, 436, 6370, 31202, 11, 311, 17782, 4871, 315, 420, 15020, 277, 323, 584, 3358, 6920, 813, 8982, 3974, 994, 430, 5334, 38199, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[21, 21], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38]]}, {\"piece_ids\": [128000, 63995, 2678, 11977, 4027, 11, 719, 279, 9462, 13766, 706, 9147, 279, 6348, 37406, 285, 311, 2586, 1633, 3345, 311, 279, 5754, 11, 323, 422, 602, 5222, 264, 2697, 23418, 11, 433, 596, 1606, 584, 2351, 304, 279, 8579, 6930, 7458, 323, 16470, 775, 374, 304, 20634, 13, 128001], \"label\": [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 4], [17, 17], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48]]}, {\"piece_ids\": [128000, 65, 1923, 648, 11, 617, 499, 3596, 1027, 311, 279, 5426, 29711, 323, 4967, 4219, 3221, 91478, 44058, 11, 289, 6723, 30, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22]]}, {\"piece_ids\": [128000, 19041, 690, 387, 5217, 4288, 58074, 315, 11731, 323, 13893, 11, 11911, 389, 279, 17149, 11, 1063, 9669, 315, 5278, 70, 8016, 323, 384, 2542, 1139, 279, 17149, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[20, 22], [24, 25], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [23, 23], [26, 26], [27, 27], [28, 28], [29, 29]]}, {\"piece_ids\": [128000, 548, 499, 5108, 1618, 30, 128001], \"label\": [2, 0, 0, 0, 0], \"span\": [[3, 3], [1, 1], [2, 2], [4, 4], [5, 5]]}, {\"piece_ids\": [128000, 9008, 41287, 15201, 30010, 1521, 10093, 304, 264, 48335, 11, 1234, 279, 88792, 315, 26283, 37431, 13, 128001], \"label\": [2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 4], [16, 16], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [17, 17]]}, {\"piece_ids\": [128000, 94323, 95146, 11, 8040, 24392, 369, 6411, 10096, 11, 1051, 9277, 520, 96862, 596, 2609, 72, 17149, 1566, 2046, 311, 1817, 1274, 33111, 505, 274, 1590, 482, 11754, 5961, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[23, 23], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30]]}, {\"piece_ids\": [128000, 1820, 10411, 91155, 660, 555, 84060, 505, 279, 11499, 2536, 482, 53840, 38997, 11, 1367, 6427, 577, 13, 308, 13, 69930, 323, 93624, 264, 60587, 90344, 482, 17843, 38729, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[15, 16], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30]]}, {\"piece_ids\": [128000, 383, 1550, 539, 636, 813, 16064, 1405, 568, 596, 2133, 311, 387, 272, 482, 482, 482, 568, 596, 304, 709, 2513, 502, 50672, 1314, 1457, 719, 568, 596, 2133, 311, 482, 482, 617, 311, 4762, 733, 1203, 311, 482, 311, 3060, 6348, 37406, 477, 8136, 482, 8136, 16083, 9121, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[36, 37], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50]]}, {\"piece_ids\": [128000, 84, 13, 274, 13, 9232, 19607, 1541, 4852, 305, 13, 436, 6370, 31202, 14407, 279, 11175, 449, 10461, 13015, 259, 3633, 1529, 1334, 323, 9232, 19607, 3980, 1885, 305, 9186, 389, 80413, 439, 436, 6370, 31202, 6052, 505, 264, 7364, 315, 6348, 37406, 11, 8136, 16083, 9121, 323, 279, 7565, 1122, 342, 14643, 5654, 13, 128001], \"label\": [9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[14, 14], [37, 37], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [49, 49], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55]]}, {\"piece_ids\": [128000, 1820, 1193, 2478, 5944, 13607, 2103, 35821, 21728, 311, 279, 6278, 11226, 617, 7319, 872, 7729, 555, 220, 2636, 311, 220, 5067, 73383, 482, 326, 10910, 482, 220, 1399, 311, 220, 5332, 603, 11441, 482, 436, 10910, 43845, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38]]}, {\"piece_ids\": [128000, 383, 482, 482, 1306, 20948, 323, 4737, 264, 10015, 7364, 315, 961, 315, 279, 8448, 11, 568, 1101, 4024, 704, 389, 311, 279, 11213, 9722, 323, 13468, 1063, 315, 279, 11213, 7677, 315, 1063, 315, 279, 282, 482, 220, 972, 14467, 430, 527, 1457, 9564, 1521, 14467, 11, 19946, 311, 32703, 461, 1306, 420, 220, 605, 482, 2305, 1317, 10739, 1097, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[49, 49], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39], [40, 40], [41, 41], [42, 42], [43, 43], [44, 44], [45, 45], [46, 46], [47, 47], [48, 48], [50, 50], [51, 51], [52, 52], [53, 53], [54, 54], [55, 55], [56, 56], [57, 57], [58, 58], [59, 59], [60, 60], [61, 61], [62, 62]]}, {\"piece_ids\": [128000, 300, 279, 27861, 62553, 291, 3347, 63421, 14016, 389, 279, 6348, 37406, 482, 37700, 11748, 3973, 11, 459, 6348, 37406, 72, 8334, 315, 922, 220, 605, 14618, 311, 813, 11013, 323, 44543, 1595, 1595, 8343, 11, 8343, 0, 4708, 128001], \"label\": [2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[4, 5], [7, 7], [1, 1], [2, 2], [3, 3], [6, 6], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35], [36, 36], [37, 37], [38, 38], [39, 39]]}, {\"piece_ids\": [128000, 30115, 11077, 7465, 11, 584, 733, 1523, 311, 279, 44844, 15140, 6201, 6246, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14]]}, {\"piece_ids\": [128000, 20670, 2019, 814, 2351, 3411, 4741, 311, 2133, 2162, 11, 902, 29658, 315, 832, 4846, 281, 13, 297, 13, 289, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21]]}, {\"piece_ids\": [128000, 906, 353, 1120, 353, 2751, 1203, 1139, 94771, 1566, 11714, 11, 1306, 1057, 10015, 220, 20, 482, 1938, 8577, 311, 63146, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[5, 6], [19, 19], [1, 1], [2, 2], [3, 3], [4, 4], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [20, 20], [21, 21], [22, 22]]}, {\"piece_ids\": [128000, 32158, 706, 912, 4623, 1405, 1077, 10177, 374, 1457, 11, 719, 9523, 311, 264, 2697, 1520, 505, 264, 9665, 11213, 65022, 11, 1364, 7020, 568, 2751, 1405, 568, 574, 2133, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[26, 26], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [27, 27], [28, 28], [29, 29], [30, 30], [31, 31]]}, {\"piece_ids\": [128000, 383, 574, 3288, 311, 2500, 8952, 449, 264, 8841, 5089, 3156, 813, 98147, 20250, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[3, 3], [1, 1], [2, 2], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15]]}, {\"piece_ids\": [128000, 72, 1097, 19781, 11, 30056, 11, 323, 602, 5387, 369, 990, 323, 636, 2162, 505, 990, 304, 279, 6453, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[13, 13], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20]]}, {\"piece_ids\": [128000, 71, 680, 1570, 10307, 10390, 323, 503, 5515, 389, 813, 13726, 12707, 11, 813, 18475, 505, 279, 6784, 482, 100141, 8334, 889, 2163, 9145, 16373, 329, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[23, 23], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [24, 24], [25, 25], [26, 26], [27, 27]]}, {\"piece_ids\": [128000, 84, 13, 274, 13, 3678, 1572, 10862, 83209, 9145, 16373, 329, 3432, 323, 1766, 22700, 315, 11742, 29076, 27227, 323, 520, 897, 483, 15921, 388, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[7, 7], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26]]}, {\"piece_ids\": [128000, 67, 2453, 780, 17629, 323, 1243, 264, 471, 2162, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [10, 10]]}, {\"piece_ids\": [128000, 30115, 11077, 7465, 11, 584, 733, 1523, 311, 279, 44844, 15140, 6201, 6246, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[6, 6], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14]]}, {\"piece_ids\": [128000, 8248, 11, 44844, 11, 520, 520, 3325, 369, 279, 22260, 304, 384, 13849, 602, 1781, 11, 44844, 11, 602, 649, 3619, 430, 912, 832, 1053, 1390, 311, 733, 1139, 482, 482, 28639, 88457, 18455, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[28, 28], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [29, 29], [30, 30], [31, 31], [32, 32], [33, 33], [34, 34], [35, 35]]}, {\"piece_ids\": [128000, 258, 27861, 323, 389, 4579, 814, 3782, 311, 279, 6424, 315, 5653, 16965, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[7, 7], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14]]}, {\"piece_ids\": [128000, 300, 577, 13, 274, 13, 8310, 7882, 41929, 3235, 279, 259, 5346, 285, 15140, 11, 6348, 37406, 285, 30010, 3235, 1202, 14286, 323, 1063, 27096, 304, 279, 3090, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[7, 7], [19, 19], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [28, 28], [29, 29]]}, {\"piece_ids\": [128000, 67, 2453, 780, 17629, 323, 1243, 264, 471, 2162, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[8, 8], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [9, 9], [10, 10]]}, {\"piece_ids\": [128000, 275, 574, 279, 1176, 5089, 311, 5425, 279, 65043, 4171, 988, 15140, 323, 1243, 21004, 10411, 1637, 311, 2949, 220, 1399, 8931, 315, 9145, 16373, 329, 13, 128001], \"label\": [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[7, 7], [15, 15], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27]]}, {\"piece_ids\": [128000, 1201, 5169, 4379, 10388, 2781, 66, 1143, 379, 9672, 1394, 12263, 279, 2816, 315, 279, 6693, 21327, 719, 16436, 311, 2019, 422, 264, 13054, 1047, 9057, 279, 25176, 13, 128001], \"label\": [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[28, 28], [11, 11], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [29, 29]]}, {\"piece_ids\": [128000, 1820, 893, 574, 12800, 1070, 1306, 11527, 2019, 568, 22130, 11440, 264, 19250, 276, 11277, 1701, 1148, 574, 5068, 311, 387, 80059, 11, 22106, 279, 36377, 311, 11722, 311, 76754, 13, 128001], \"label\": [2, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[28, 28], [4, 4], [1, 1], [2, 2], [3, 3], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [16, 16], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22], [23, 23], [24, 24], [25, 25], [26, 26], [27, 27], [29, 29], [30, 30], [31, 31]]}, {\"piece_ids\": [128000, 2000, 279, 1828, 220, 717, 4207, 1139, 279, 6693, 11, 25761, 505, 279, 19115, 690, 11722, 25664, 927, 8136, 16083, 9121, 13, 128001], \"label\": [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"span\": [[16, 16], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11], [12, 12], [13, 13], [14, 14], [15, 15], [17, 17], [18, 18], [19, 19], [20, 20], [21, 21], [22, 22]]}]}\"\"\"\n",
    "text[108770:108790]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0]), tensor([0, 0]), tensor([0, 1]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(\n",
    "    torch.tensor([[[1,2,2]]]) == torch.tensor([[[1,2,3]]])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 2])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "old_span = torch.tensor([[115, 115],\n",
    "        [ 85,  85],\n",
    "        [ 86,  86],\n",
    "        [ 87,  87],\n",
    "        [ 88,  88],\n",
    "        [ 89,  89],\n",
    "        [ 90,  90],\n",
    "        [ 91,  91],\n",
    "        [ 92,  92],\n",
    "        [ 93,  93],\n",
    "        [ 94,  94],\n",
    "        [ 95,  95],\n",
    "        [ 96,  96],\n",
    "        [ 97,  97],\n",
    "        [ 98,  98],\n",
    "        [ 99,  99],\n",
    "        [100, 100],\n",
    "        [101, 101],\n",
    "        [102, 102],\n",
    "        [103, 103],\n",
    "        [104, 104],\n",
    "        [105, 105],\n",
    "        [106, 106],\n",
    "        [107, 107],\n",
    "        [108, 108],\n",
    "        [109, 109],\n",
    "        [110, 110],\n",
    "        [111, 111],\n",
    "        [112, 112],\n",
    "        [113, 113],\n",
    "        [114, 114],\n",
    "        [116, 116],\n",
    "        [117, 117],\n",
    "        [118, 118],\n",
    "        [119, 119],\n",
    "        [120, 120],\n",
    "        [121, 121],\n",
    "        [122, 122],\n",
    "        [123, 123],\n",
    "        [124, 124],\n",
    "        [125, 125],\n",
    "        [126, 126],\n",
    "        [127, 127],\n",
    "        [128, 128],\n",
    "        [129, 129],\n",
    "        [130, 130],\n",
    "        [131, 131],\n",
    "        [134, 134],\n",
    "        [135, 135]])\n",
    "\n",
    "old_span.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([133, 133])\n",
      "tensor([132, 132])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 2])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.randperm(51).unsqueeze(0).unsqueeze(0) + 135 - 51 + 1\n",
    "new_span = torch.where(old_span.unsqueeze(2).cpu() == z.cpu())[2].view(-1, 2) + 135 - 51 + 1\n",
    "\n",
    "for span in new_span:\n",
    "    if span not in old_span:\n",
    "        print(span)\n",
    "\n",
    "new_span.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[100, 116, 126,  84, 106,  94,  95, 123, 104, 105,  97, 131, 108,  90,\n",
       "          129, 113, 125, 111, 132, 117, 124,  92, 128, 135,  85,  91,  88, 101,\n",
       "          134, 114, 109, 102, 130,  93,  99,  98, 103, 118, 122,  87,  96,  89,\n",
       "          127, 110, 133, 119, 115, 112, 107,  86, 121, 120]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([ 85,  85,  86,  86,  87,  87,  88,  88,  89,  89,  90,  90,  91,  91,\n",
       "         92,  92,  93,  93,  94,  94,  95,  95,  96,  96,  97,  97,  98,  98,\n",
       "         99,  99, 100, 100, 101, 101, 102, 102, 103, 103, 104, 104, 105, 105,\n",
       "        106, 106, 107, 107, 108, 108, 109, 109, 110, 110, 111, 111, 112, 112,\n",
       "        113, 113, 114, 114, 115, 115, 116, 116, 117, 117, 118, 118, 119, 119,\n",
       "        120, 120, 121, 121, 122, 122, 124, 124, 125, 125, 127, 127, 128, 128,\n",
       "        129, 129, 130, 130, 131, 131, 132, 132, 133, 133, 134, 134, 135, 135]),\n",
       "indices=tensor([90, 91, 77, 76, 72, 73, 89, 88, 36, 37, 16, 17, 61, 60, 85, 84, 18, 19,\n",
       "        33, 32, 55, 54, 70, 71, 28, 29, 65, 64, 42, 43, 57, 56, 68, 69, 62, 63,\n",
       "        80, 81, 93, 92, 27, 26, 35, 34, 97, 96, 95, 94, 66, 67, 87, 86, 75, 74,\n",
       "        52, 53, 49, 48,  2,  3, 11, 10, 51, 50,  1,  0,  9,  8, 78, 79, 12, 13,\n",
       "        39, 38, 45, 44, 14, 15, 20, 21, 58, 59,  7,  6, 47, 46, 30, 31, 82, 83,\n",
       "        24, 25, 23, 22, 41, 40,  5,  4]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_span.view(-1).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51, 2])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_span.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 2, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da_span[0].unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 602, 1781, 430, 279, 2944, 16470, 304, 279, 10007, 482, 482, 499, 1440, 11, 1176, 315, 682, 11, 584, 1051, 482, 482, 994, 26875, 3817, 938, 974, 43521, 574, 16689, 4872, 11, 584, 1047, 1027, 5496, 1148, 584, 3463, 574, 2103, 264, 69912, 7140, 1306, 279, 8431, 4208, 13, 128001]\n"
     ]
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA_VISIBLE_DEVICES=1 CUDA_LAUNCH_BLOCKING=1 python train_first_task.py                 --data-root ./data_incremental                 --dataset ACE                 --backbone bert-base-uncased                 --lr 2e-5                 --decay 1e-4                 --no-freeze-bert                 --shot-num 1                 --batch-size 4                 --device cuda:0                 --log                 --log-dir ./outputs/log_incremental/temp7_submax/first_wo_UCL+TCL/                 --log-name ashuffle_lnone_r5                 --dweight_loss                 --rep-aug mean                 --distill mul                 --epoch 20                 --class-num 20                 --single-label                 --cl-aug shuffle                 --aug-repeat-times 5                 --joint-da-loss none                 --sub-max                 --cl_temp 0.07                 --tlcl                 --ucl                 --skip-first-cl ucl+tlcl                 --perm-id 0                 --early-stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
